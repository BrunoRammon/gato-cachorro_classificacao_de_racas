{"cells":[{"cell_type":"markdown","metadata":{"id":"yXfd3wEQLwmH"},"source":["# Initial setup"]},{"cell_type":"code","source":["# install \n","%pip install scikit-posthocs\n","%pip install scipy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tubfn7bqx2V5","executionInfo":{"status":"ok","timestamp":1670978253051,"user_tz":180,"elapsed":7164,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"ab0d4add-c551-4acd-e640-5392e95d8050"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-posthocs in /usr/local/lib/python3.8/dist-packages (0.7.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (0.11.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (1.21.6)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (0.12.2)\n","Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (1.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (1.7.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from scikit-posthocs) (3.2.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20.0->scikit-posthocs) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-posthocs) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-posthocs) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-posthocs) (0.11.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->scikit-posthocs) (0.5.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"]}]},{"cell_type":"code","source":["# general use\n","import itertools\n","from enum import Enum\n","from copy import deepcopy\n","import regex as re\n","import pandas as pd\n","import numpy as np\n","\n","# simple classifiers\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","# ensembles classifiers\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import StackingClassifier\n","\n","# scalers\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler  \n","\n","# cross validation techniques\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn import metrics\n","\n","# for statistical test\n","from scipy import stats\n","import scikit_posthocs as sp"],"metadata":{"id":"hGFPdQ1VVn_h","executionInfo":{"status":"ok","timestamp":1670978254406,"user_tz":180,"elapsed":1365,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3889,"status":"ok","timestamp":1670978258291,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"S-ZktyOkWi5y","outputId":"0eb01a37-93f1-4f35-bcff-8a63c47691ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Programming/Data Science/PES-IMD/Aprendizado de Máquina/Trabalho/Trab_AM/gato-cachorro_classificacao_de_racas\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/Programming/Data Science/PES-IMD/Aprendizado de Máquina/Trabalho/Trab_AM/gato-cachorro_classificacao_de_racas/'"]},{"cell_type":"code","source":["path_to_datasets = './processed_datasets/'\n","path_to_accuracies = './accuracies/'"],"metadata":{"id":"tad_4pZOo_gO","executionInfo":{"status":"ok","timestamp":1670978258292,"user_tz":180,"elapsed":16,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-kf2kqdmtKO"},"source":["# Datasets"]},{"cell_type":"markdown","metadata":{"id":"XQaGYrqT8QpA"},"source":["## Normal data set d = 1764"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":526,"status":"ok","timestamp":1670978258805,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"EBvzgGOJ8LKX","outputId":"4bdfdc47-0fc9-40d8-a157-c3f4d7186f3a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.084298  0.055577  0.052653  0.051070  0.100116  0.111726  0.085606   \n","1  0.240130  0.099940  0.107868  0.240130  0.240130  0.240130  0.085054   \n","2  0.296857  0.296857  0.192027  0.118093  0.144822  0.078502  0.067119   \n","3  0.222998  0.140840  0.159199  0.105568  0.190843  0.129682  0.163091   \n","4  0.278233  0.028802  0.004027  0.006154  0.017805  0.008525  0.007660   \n","5  0.252442  0.067413  0.020861  0.026860  0.137779  0.071512  0.024365   \n","6  0.225421  0.260662  0.122048  0.041961  0.075550  0.013764  0.038639   \n","7  0.042428  0.012829  0.051054  0.138152  0.297832  0.094548  0.018066   \n","8  0.218417  0.184951  0.218417  0.176171  0.218417  0.148506  0.122361   \n","9  0.224950  0.184881  0.155280  0.212940  0.133371  0.052802  0.054540   \n","\n","          7         8         9  ...      1755      1756      1757      1758  \\\n","0  0.071323  0.062354  0.131749  ...  0.186781  0.167077  0.123062  0.206317   \n","1  0.138299  0.170739  0.205619  ...  0.248859  0.108594  0.101801  0.058171   \n","2  0.102928  0.244927  0.073403  ...  0.077877  0.023129  0.057161  0.080489   \n","3  0.222998  0.158737  0.222998  ...  0.185352  0.144374  0.130847  0.150475   \n","4  0.049038  0.325160  0.258007  ...  0.248447  0.231704  0.096816  0.054017   \n","5  0.047084  0.380612  0.380612  ...  0.215076  0.148538  0.158630  0.189096   \n","6  0.025091  0.039463  0.262798  ...  0.026674  0.014406  0.013655  0.055924   \n","7  0.018478  0.004392  0.024748  ...  0.102495  0.069838  0.082066  0.166017   \n","8  0.079024  0.146140  0.166223  ...  0.205706  0.132222  0.136953  0.088043   \n","9  0.094103  0.154376  0.210799  ...  0.148467  0.144005  0.238637  0.238637   \n","\n","       1759      1760      1761      1762      1763               class  \n","0  0.214587  0.204777  0.210161  0.126280  0.123178  german_shorthaired  \n","1  0.118594  0.088637  0.110307  0.078088  0.103826          Maine_Coon  \n","2  0.364878  0.282017  0.133116  0.154003  0.061886             Siamese  \n","3  0.211966  0.232555  0.185272  0.211561  0.103058        newfoundland  \n","4  0.185490  0.059698  0.134580  0.248447  0.248447       saint_bernard  \n","5  0.215076  0.194341  0.147962  0.211813  0.215076        newfoundland  \n","6  0.307993  0.339604  0.122119  0.033844  0.021782          Maine_Coon  \n","7  0.273593  0.182716  0.119556  0.125424  0.070378             Siamese  \n","8  0.178162  0.127782  0.193361  0.196591  0.151919       saint_bernard  \n","9  0.238637  0.091228  0.066691  0.124647  0.100731        newfoundland  \n","\n","[10 rows x 1765 columns]"],"text/html":["\n","  <div id=\"df-3cbf7f07-6404-4533-9b37-02b595d52282\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>1755</th>\n","      <th>1756</th>\n","      <th>1757</th>\n","      <th>1758</th>\n","      <th>1759</th>\n","      <th>1760</th>\n","      <th>1761</th>\n","      <th>1762</th>\n","      <th>1763</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.084298</td>\n","      <td>0.055577</td>\n","      <td>0.052653</td>\n","      <td>0.051070</td>\n","      <td>0.100116</td>\n","      <td>0.111726</td>\n","      <td>0.085606</td>\n","      <td>0.071323</td>\n","      <td>0.062354</td>\n","      <td>0.131749</td>\n","      <td>...</td>\n","      <td>0.186781</td>\n","      <td>0.167077</td>\n","      <td>0.123062</td>\n","      <td>0.206317</td>\n","      <td>0.214587</td>\n","      <td>0.204777</td>\n","      <td>0.210161</td>\n","      <td>0.126280</td>\n","      <td>0.123178</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.240130</td>\n","      <td>0.099940</td>\n","      <td>0.107868</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.085054</td>\n","      <td>0.138299</td>\n","      <td>0.170739</td>\n","      <td>0.205619</td>\n","      <td>...</td>\n","      <td>0.248859</td>\n","      <td>0.108594</td>\n","      <td>0.101801</td>\n","      <td>0.058171</td>\n","      <td>0.118594</td>\n","      <td>0.088637</td>\n","      <td>0.110307</td>\n","      <td>0.078088</td>\n","      <td>0.103826</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.296857</td>\n","      <td>0.296857</td>\n","      <td>0.192027</td>\n","      <td>0.118093</td>\n","      <td>0.144822</td>\n","      <td>0.078502</td>\n","      <td>0.067119</td>\n","      <td>0.102928</td>\n","      <td>0.244927</td>\n","      <td>0.073403</td>\n","      <td>...</td>\n","      <td>0.077877</td>\n","      <td>0.023129</td>\n","      <td>0.057161</td>\n","      <td>0.080489</td>\n","      <td>0.364878</td>\n","      <td>0.282017</td>\n","      <td>0.133116</td>\n","      <td>0.154003</td>\n","      <td>0.061886</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.222998</td>\n","      <td>0.140840</td>\n","      <td>0.159199</td>\n","      <td>0.105568</td>\n","      <td>0.190843</td>\n","      <td>0.129682</td>\n","      <td>0.163091</td>\n","      <td>0.222998</td>\n","      <td>0.158737</td>\n","      <td>0.222998</td>\n","      <td>...</td>\n","      <td>0.185352</td>\n","      <td>0.144374</td>\n","      <td>0.130847</td>\n","      <td>0.150475</td>\n","      <td>0.211966</td>\n","      <td>0.232555</td>\n","      <td>0.185272</td>\n","      <td>0.211561</td>\n","      <td>0.103058</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.278233</td>\n","      <td>0.028802</td>\n","      <td>0.004027</td>\n","      <td>0.006154</td>\n","      <td>0.017805</td>\n","      <td>0.008525</td>\n","      <td>0.007660</td>\n","      <td>0.049038</td>\n","      <td>0.325160</td>\n","      <td>0.258007</td>\n","      <td>...</td>\n","      <td>0.248447</td>\n","      <td>0.231704</td>\n","      <td>0.096816</td>\n","      <td>0.054017</td>\n","      <td>0.185490</td>\n","      <td>0.059698</td>\n","      <td>0.134580</td>\n","      <td>0.248447</td>\n","      <td>0.248447</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.252442</td>\n","      <td>0.067413</td>\n","      <td>0.020861</td>\n","      <td>0.026860</td>\n","      <td>0.137779</td>\n","      <td>0.071512</td>\n","      <td>0.024365</td>\n","      <td>0.047084</td>\n","      <td>0.380612</td>\n","      <td>0.380612</td>\n","      <td>...</td>\n","      <td>0.215076</td>\n","      <td>0.148538</td>\n","      <td>0.158630</td>\n","      <td>0.189096</td>\n","      <td>0.215076</td>\n","      <td>0.194341</td>\n","      <td>0.147962</td>\n","      <td>0.211813</td>\n","      <td>0.215076</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.225421</td>\n","      <td>0.260662</td>\n","      <td>0.122048</td>\n","      <td>0.041961</td>\n","      <td>0.075550</td>\n","      <td>0.013764</td>\n","      <td>0.038639</td>\n","      <td>0.025091</td>\n","      <td>0.039463</td>\n","      <td>0.262798</td>\n","      <td>...</td>\n","      <td>0.026674</td>\n","      <td>0.014406</td>\n","      <td>0.013655</td>\n","      <td>0.055924</td>\n","      <td>0.307993</td>\n","      <td>0.339604</td>\n","      <td>0.122119</td>\n","      <td>0.033844</td>\n","      <td>0.021782</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.042428</td>\n","      <td>0.012829</td>\n","      <td>0.051054</td>\n","      <td>0.138152</td>\n","      <td>0.297832</td>\n","      <td>0.094548</td>\n","      <td>0.018066</td>\n","      <td>0.018478</td>\n","      <td>0.004392</td>\n","      <td>0.024748</td>\n","      <td>...</td>\n","      <td>0.102495</td>\n","      <td>0.069838</td>\n","      <td>0.082066</td>\n","      <td>0.166017</td>\n","      <td>0.273593</td>\n","      <td>0.182716</td>\n","      <td>0.119556</td>\n","      <td>0.125424</td>\n","      <td>0.070378</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.218417</td>\n","      <td>0.184951</td>\n","      <td>0.218417</td>\n","      <td>0.176171</td>\n","      <td>0.218417</td>\n","      <td>0.148506</td>\n","      <td>0.122361</td>\n","      <td>0.079024</td>\n","      <td>0.146140</td>\n","      <td>0.166223</td>\n","      <td>...</td>\n","      <td>0.205706</td>\n","      <td>0.132222</td>\n","      <td>0.136953</td>\n","      <td>0.088043</td>\n","      <td>0.178162</td>\n","      <td>0.127782</td>\n","      <td>0.193361</td>\n","      <td>0.196591</td>\n","      <td>0.151919</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.224950</td>\n","      <td>0.184881</td>\n","      <td>0.155280</td>\n","      <td>0.212940</td>\n","      <td>0.133371</td>\n","      <td>0.052802</td>\n","      <td>0.054540</td>\n","      <td>0.094103</td>\n","      <td>0.154376</td>\n","      <td>0.210799</td>\n","      <td>...</td>\n","      <td>0.148467</td>\n","      <td>0.144005</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.091228</td>\n","      <td>0.066691</td>\n","      <td>0.124647</td>\n","      <td>0.100731</td>\n","      <td>newfoundland</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 1765 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cbf7f07-6404-4533-9b37-02b595d52282')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3cbf7f07-6404-4533-9b37-02b595d52282 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3cbf7f07-6404-4533-9b37-02b595d52282');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["#getting the attributes of each instances\n","d = 1764\n","df = pd.read_csv(path_to_datasets+f\"dataset_normal_d={d}.csv\")\n","df.head(10)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":4327,"status":"ok","timestamp":1670978263121,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"3o-5-TXvso2q","outputId":"d5fdfcc5-de9a-4248-daa0-388df6e77d99"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 0            1            2            3            4  \\\n","count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n","mean      0.180023     0.103617     0.101801     0.116420     0.182361   \n","std       0.102097     0.081473     0.077841     0.088372     0.104334   \n","min       0.000000     0.000000     0.000000     0.000000     0.000000   \n","25%       0.098912     0.036296     0.037418     0.041642     0.092764   \n","50%       0.181239     0.084809     0.087148     0.103095     0.190728   \n","75%       0.249903     0.154655     0.149590     0.172883     0.254081   \n","max       0.697552     0.395436     0.359722     0.402484     0.560289   \n","\n","                 5            6            7            8            9  ...  \\\n","count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n","mean      0.105743     0.088333     0.094846     0.145186     0.178316  ...   \n","std       0.083224     0.072064     0.075291     0.110418     0.105871  ...   \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n","25%       0.037770     0.027705     0.032847     0.052846     0.088564  ...   \n","50%       0.090695     0.074603     0.079396     0.122825     0.187120  ...   \n","75%       0.158340     0.133741     0.139796     0.226516     0.249588  ...   \n","max       0.423818     0.363487     0.357271     0.578341     0.534035  ...   \n","\n","              1754         1755         1756         1757         1758  \\\n","count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n","mean      0.133977     0.167514     0.109069     0.111877     0.124297   \n","std       0.086757     0.084798     0.073132     0.072091     0.075169   \n","min       0.000000     0.000000     0.000000     0.000000     0.000000   \n","25%       0.067038     0.104901     0.051726     0.054771     0.064209   \n","50%       0.122892     0.170359     0.100275     0.102715     0.119474   \n","75%       0.191783     0.221720     0.153252     0.156416     0.175786   \n","max       0.474450     0.499047     0.465886     0.424095     0.370067   \n","\n","              1759         1760         1761         1762         1763  \n","count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n","mean      0.190936     0.134304     0.125938     0.119377     0.127265  \n","std       0.088242     0.081264     0.081391     0.081785     0.085108  \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  \n","25%       0.129946     0.069533     0.058347     0.052914     0.060822  \n","50%       0.206482     0.127596     0.119479     0.111929     0.115310  \n","75%       0.243347     0.194349     0.179840     0.169847     0.184964  \n","max       0.686201     0.399498     0.414513     0.382718     0.436347  \n","\n","[8 rows x 1764 columns]"],"text/html":["\n","  <div id=\"df-5426b57e-25a8-4748-99fd-306fa6935633\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>1754</th>\n","      <th>1755</th>\n","      <th>1756</th>\n","      <th>1757</th>\n","      <th>1758</th>\n","      <th>1759</th>\n","      <th>1760</th>\n","      <th>1761</th>\n","      <th>1762</th>\n","      <th>1763</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>...</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","      <td>1000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.180023</td>\n","      <td>0.103617</td>\n","      <td>0.101801</td>\n","      <td>0.116420</td>\n","      <td>0.182361</td>\n","      <td>0.105743</td>\n","      <td>0.088333</td>\n","      <td>0.094846</td>\n","      <td>0.145186</td>\n","      <td>0.178316</td>\n","      <td>...</td>\n","      <td>0.133977</td>\n","      <td>0.167514</td>\n","      <td>0.109069</td>\n","      <td>0.111877</td>\n","      <td>0.124297</td>\n","      <td>0.190936</td>\n","      <td>0.134304</td>\n","      <td>0.125938</td>\n","      <td>0.119377</td>\n","      <td>0.127265</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.102097</td>\n","      <td>0.081473</td>\n","      <td>0.077841</td>\n","      <td>0.088372</td>\n","      <td>0.104334</td>\n","      <td>0.083224</td>\n","      <td>0.072064</td>\n","      <td>0.075291</td>\n","      <td>0.110418</td>\n","      <td>0.105871</td>\n","      <td>...</td>\n","      <td>0.086757</td>\n","      <td>0.084798</td>\n","      <td>0.073132</td>\n","      <td>0.072091</td>\n","      <td>0.075169</td>\n","      <td>0.088242</td>\n","      <td>0.081264</td>\n","      <td>0.081391</td>\n","      <td>0.081785</td>\n","      <td>0.085108</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.098912</td>\n","      <td>0.036296</td>\n","      <td>0.037418</td>\n","      <td>0.041642</td>\n","      <td>0.092764</td>\n","      <td>0.037770</td>\n","      <td>0.027705</td>\n","      <td>0.032847</td>\n","      <td>0.052846</td>\n","      <td>0.088564</td>\n","      <td>...</td>\n","      <td>0.067038</td>\n","      <td>0.104901</td>\n","      <td>0.051726</td>\n","      <td>0.054771</td>\n","      <td>0.064209</td>\n","      <td>0.129946</td>\n","      <td>0.069533</td>\n","      <td>0.058347</td>\n","      <td>0.052914</td>\n","      <td>0.060822</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.181239</td>\n","      <td>0.084809</td>\n","      <td>0.087148</td>\n","      <td>0.103095</td>\n","      <td>0.190728</td>\n","      <td>0.090695</td>\n","      <td>0.074603</td>\n","      <td>0.079396</td>\n","      <td>0.122825</td>\n","      <td>0.187120</td>\n","      <td>...</td>\n","      <td>0.122892</td>\n","      <td>0.170359</td>\n","      <td>0.100275</td>\n","      <td>0.102715</td>\n","      <td>0.119474</td>\n","      <td>0.206482</td>\n","      <td>0.127596</td>\n","      <td>0.119479</td>\n","      <td>0.111929</td>\n","      <td>0.115310</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.249903</td>\n","      <td>0.154655</td>\n","      <td>0.149590</td>\n","      <td>0.172883</td>\n","      <td>0.254081</td>\n","      <td>0.158340</td>\n","      <td>0.133741</td>\n","      <td>0.139796</td>\n","      <td>0.226516</td>\n","      <td>0.249588</td>\n","      <td>...</td>\n","      <td>0.191783</td>\n","      <td>0.221720</td>\n","      <td>0.153252</td>\n","      <td>0.156416</td>\n","      <td>0.175786</td>\n","      <td>0.243347</td>\n","      <td>0.194349</td>\n","      <td>0.179840</td>\n","      <td>0.169847</td>\n","      <td>0.184964</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.697552</td>\n","      <td>0.395436</td>\n","      <td>0.359722</td>\n","      <td>0.402484</td>\n","      <td>0.560289</td>\n","      <td>0.423818</td>\n","      <td>0.363487</td>\n","      <td>0.357271</td>\n","      <td>0.578341</td>\n","      <td>0.534035</td>\n","      <td>...</td>\n","      <td>0.474450</td>\n","      <td>0.499047</td>\n","      <td>0.465886</td>\n","      <td>0.424095</td>\n","      <td>0.370067</td>\n","      <td>0.686201</td>\n","      <td>0.399498</td>\n","      <td>0.414513</td>\n","      <td>0.382718</td>\n","      <td>0.436347</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 1764 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5426b57e-25a8-4748-99fd-306fa6935633')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5426b57e-25a8-4748-99fd-306fa6935633 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5426b57e-25a8-4748-99fd-306fa6935633');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["df.describe()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1670978263122,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"2a5dSEC6uYT5"},"outputs":[],"source":["X_normal = df[[str(i) for i in range(1764)]]\n","y_normal = df['class']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1670978263122,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"0D6gJzGcxhTd","outputId":"99a5993b-69d2-4622-f165-09df6eaa5031"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.084298  0.055577  0.052653  0.051070  0.100116  0.111726  0.085606   \n","1  0.240130  0.099940  0.107868  0.240130  0.240130  0.240130  0.085054   \n","2  0.296857  0.296857  0.192027  0.118093  0.144822  0.078502  0.067119   \n","3  0.222998  0.140840  0.159199  0.105568  0.190843  0.129682  0.163091   \n","4  0.278233  0.028802  0.004027  0.006154  0.017805  0.008525  0.007660   \n","5  0.252442  0.067413  0.020861  0.026860  0.137779  0.071512  0.024365   \n","6  0.225421  0.260662  0.122048  0.041961  0.075550  0.013764  0.038639   \n","7  0.042428  0.012829  0.051054  0.138152  0.297832  0.094548  0.018066   \n","8  0.218417  0.184951  0.218417  0.176171  0.218417  0.148506  0.122361   \n","9  0.224950  0.184881  0.155280  0.212940  0.133371  0.052802  0.054540   \n","\n","          7         8         9  ...      1754      1755      1756      1757  \\\n","0  0.071323  0.062354  0.131749  ...  0.141227  0.186781  0.167077  0.123062   \n","1  0.138299  0.170739  0.205619  ...  0.238072  0.248859  0.108594  0.101801   \n","2  0.102928  0.244927  0.073403  ...  0.026350  0.077877  0.023129  0.057161   \n","3  0.222998  0.158737  0.222998  ...  0.131139  0.185352  0.144374  0.130847   \n","4  0.049038  0.325160  0.258007  ...  0.083221  0.248447  0.231704  0.096816   \n","5  0.047084  0.380612  0.380612  ...  0.181960  0.215076  0.148538  0.158630   \n","6  0.025091  0.039463  0.262798  ...  0.031397  0.026674  0.014406  0.013655   \n","7  0.018478  0.004392  0.024748  ...  0.083059  0.102495  0.069838  0.082066   \n","8  0.079024  0.146140  0.166223  ...  0.094529  0.205706  0.132222  0.136953   \n","9  0.094103  0.154376  0.210799  ...  0.105730  0.148467  0.144005  0.238637   \n","\n","       1758      1759      1760      1761      1762      1763  \n","0  0.206317  0.214587  0.204777  0.210161  0.126280  0.123178  \n","1  0.058171  0.118594  0.088637  0.110307  0.078088  0.103826  \n","2  0.080489  0.364878  0.282017  0.133116  0.154003  0.061886  \n","3  0.150475  0.211966  0.232555  0.185272  0.211561  0.103058  \n","4  0.054017  0.185490  0.059698  0.134580  0.248447  0.248447  \n","5  0.189096  0.215076  0.194341  0.147962  0.211813  0.215076  \n","6  0.055924  0.307993  0.339604  0.122119  0.033844  0.021782  \n","7  0.166017  0.273593  0.182716  0.119556  0.125424  0.070378  \n","8  0.088043  0.178162  0.127782  0.193361  0.196591  0.151919  \n","9  0.238637  0.238637  0.091228  0.066691  0.124647  0.100731  \n","\n","[10 rows x 1764 columns]"],"text/html":["\n","  <div id=\"df-282715a1-d650-41a8-a8a6-7481a36bc651\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>1754</th>\n","      <th>1755</th>\n","      <th>1756</th>\n","      <th>1757</th>\n","      <th>1758</th>\n","      <th>1759</th>\n","      <th>1760</th>\n","      <th>1761</th>\n","      <th>1762</th>\n","      <th>1763</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.084298</td>\n","      <td>0.055577</td>\n","      <td>0.052653</td>\n","      <td>0.051070</td>\n","      <td>0.100116</td>\n","      <td>0.111726</td>\n","      <td>0.085606</td>\n","      <td>0.071323</td>\n","      <td>0.062354</td>\n","      <td>0.131749</td>\n","      <td>...</td>\n","      <td>0.141227</td>\n","      <td>0.186781</td>\n","      <td>0.167077</td>\n","      <td>0.123062</td>\n","      <td>0.206317</td>\n","      <td>0.214587</td>\n","      <td>0.204777</td>\n","      <td>0.210161</td>\n","      <td>0.126280</td>\n","      <td>0.123178</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.240130</td>\n","      <td>0.099940</td>\n","      <td>0.107868</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.085054</td>\n","      <td>0.138299</td>\n","      <td>0.170739</td>\n","      <td>0.205619</td>\n","      <td>...</td>\n","      <td>0.238072</td>\n","      <td>0.248859</td>\n","      <td>0.108594</td>\n","      <td>0.101801</td>\n","      <td>0.058171</td>\n","      <td>0.118594</td>\n","      <td>0.088637</td>\n","      <td>0.110307</td>\n","      <td>0.078088</td>\n","      <td>0.103826</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.296857</td>\n","      <td>0.296857</td>\n","      <td>0.192027</td>\n","      <td>0.118093</td>\n","      <td>0.144822</td>\n","      <td>0.078502</td>\n","      <td>0.067119</td>\n","      <td>0.102928</td>\n","      <td>0.244927</td>\n","      <td>0.073403</td>\n","      <td>...</td>\n","      <td>0.026350</td>\n","      <td>0.077877</td>\n","      <td>0.023129</td>\n","      <td>0.057161</td>\n","      <td>0.080489</td>\n","      <td>0.364878</td>\n","      <td>0.282017</td>\n","      <td>0.133116</td>\n","      <td>0.154003</td>\n","      <td>0.061886</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.222998</td>\n","      <td>0.140840</td>\n","      <td>0.159199</td>\n","      <td>0.105568</td>\n","      <td>0.190843</td>\n","      <td>0.129682</td>\n","      <td>0.163091</td>\n","      <td>0.222998</td>\n","      <td>0.158737</td>\n","      <td>0.222998</td>\n","      <td>...</td>\n","      <td>0.131139</td>\n","      <td>0.185352</td>\n","      <td>0.144374</td>\n","      <td>0.130847</td>\n","      <td>0.150475</td>\n","      <td>0.211966</td>\n","      <td>0.232555</td>\n","      <td>0.185272</td>\n","      <td>0.211561</td>\n","      <td>0.103058</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.278233</td>\n","      <td>0.028802</td>\n","      <td>0.004027</td>\n","      <td>0.006154</td>\n","      <td>0.017805</td>\n","      <td>0.008525</td>\n","      <td>0.007660</td>\n","      <td>0.049038</td>\n","      <td>0.325160</td>\n","      <td>0.258007</td>\n","      <td>...</td>\n","      <td>0.083221</td>\n","      <td>0.248447</td>\n","      <td>0.231704</td>\n","      <td>0.096816</td>\n","      <td>0.054017</td>\n","      <td>0.185490</td>\n","      <td>0.059698</td>\n","      <td>0.134580</td>\n","      <td>0.248447</td>\n","      <td>0.248447</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.252442</td>\n","      <td>0.067413</td>\n","      <td>0.020861</td>\n","      <td>0.026860</td>\n","      <td>0.137779</td>\n","      <td>0.071512</td>\n","      <td>0.024365</td>\n","      <td>0.047084</td>\n","      <td>0.380612</td>\n","      <td>0.380612</td>\n","      <td>...</td>\n","      <td>0.181960</td>\n","      <td>0.215076</td>\n","      <td>0.148538</td>\n","      <td>0.158630</td>\n","      <td>0.189096</td>\n","      <td>0.215076</td>\n","      <td>0.194341</td>\n","      <td>0.147962</td>\n","      <td>0.211813</td>\n","      <td>0.215076</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.225421</td>\n","      <td>0.260662</td>\n","      <td>0.122048</td>\n","      <td>0.041961</td>\n","      <td>0.075550</td>\n","      <td>0.013764</td>\n","      <td>0.038639</td>\n","      <td>0.025091</td>\n","      <td>0.039463</td>\n","      <td>0.262798</td>\n","      <td>...</td>\n","      <td>0.031397</td>\n","      <td>0.026674</td>\n","      <td>0.014406</td>\n","      <td>0.013655</td>\n","      <td>0.055924</td>\n","      <td>0.307993</td>\n","      <td>0.339604</td>\n","      <td>0.122119</td>\n","      <td>0.033844</td>\n","      <td>0.021782</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.042428</td>\n","      <td>0.012829</td>\n","      <td>0.051054</td>\n","      <td>0.138152</td>\n","      <td>0.297832</td>\n","      <td>0.094548</td>\n","      <td>0.018066</td>\n","      <td>0.018478</td>\n","      <td>0.004392</td>\n","      <td>0.024748</td>\n","      <td>...</td>\n","      <td>0.083059</td>\n","      <td>0.102495</td>\n","      <td>0.069838</td>\n","      <td>0.082066</td>\n","      <td>0.166017</td>\n","      <td>0.273593</td>\n","      <td>0.182716</td>\n","      <td>0.119556</td>\n","      <td>0.125424</td>\n","      <td>0.070378</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.218417</td>\n","      <td>0.184951</td>\n","      <td>0.218417</td>\n","      <td>0.176171</td>\n","      <td>0.218417</td>\n","      <td>0.148506</td>\n","      <td>0.122361</td>\n","      <td>0.079024</td>\n","      <td>0.146140</td>\n","      <td>0.166223</td>\n","      <td>...</td>\n","      <td>0.094529</td>\n","      <td>0.205706</td>\n","      <td>0.132222</td>\n","      <td>0.136953</td>\n","      <td>0.088043</td>\n","      <td>0.178162</td>\n","      <td>0.127782</td>\n","      <td>0.193361</td>\n","      <td>0.196591</td>\n","      <td>0.151919</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.224950</td>\n","      <td>0.184881</td>\n","      <td>0.155280</td>\n","      <td>0.212940</td>\n","      <td>0.133371</td>\n","      <td>0.052802</td>\n","      <td>0.054540</td>\n","      <td>0.094103</td>\n","      <td>0.154376</td>\n","      <td>0.210799</td>\n","      <td>...</td>\n","      <td>0.105730</td>\n","      <td>0.148467</td>\n","      <td>0.144005</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.091228</td>\n","      <td>0.066691</td>\n","      <td>0.124647</td>\n","      <td>0.100731</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 1764 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-282715a1-d650-41a8-a8a6-7481a36bc651')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-282715a1-d650-41a8-a8a6-7481a36bc651 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-282715a1-d650-41a8-a8a6-7481a36bc651');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["X_normal.head(10)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1670978263123,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"4GaYloFvxiMd","outputId":"56cccb3a-069c-4e82-abe4-b567074da0ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    german_shorthaired\n","1            Maine_Coon\n","2               Siamese\n","3          newfoundland\n","4         saint_bernard\n","5          newfoundland\n","6            Maine_Coon\n","7               Siamese\n","8         saint_bernard\n","9          newfoundland\n","Name: class, dtype: object"]},"metadata":{},"execution_count":10}],"source":["y_normal.head(10)"]},{"cell_type":"markdown","metadata":{"id":"7yLhncZ-aS4U"},"source":["## Normal dataset d = 900"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":836,"status":"ok","timestamp":1670978263941,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"N1UdjJhAaS4Z","outputId":"d464067f-7de1-4a9d-82cb-c670f29fa5c8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.192672  0.028051  0.036526  0.150926  0.280795  0.082921  0.036948   \n","1  0.142662  0.123226  0.116038  0.303666  0.303666  0.071292  0.049766   \n","2  0.133335  0.102938  0.108485  0.184473  0.264377  0.130174  0.061767   \n","3  0.217431  0.051086  0.106189  0.107343  0.326340  0.217139  0.161545   \n","4  0.008161  0.012362  0.020602  0.033756  0.334871  0.072182  0.015856   \n","5  0.023072  0.008885  0.020361  0.348199  0.348199  0.057047  0.007032   \n","6  0.056318  0.042170  0.102166  0.217575  0.261892  0.261892  0.100534   \n","7  0.221830  0.148585  0.077969  0.059769  0.090290  0.096473  0.096775   \n","8  0.259639  0.223354  0.259639  0.072631  0.165941  0.062421  0.038767   \n","9  0.011779  0.004259  0.010007  0.018802  0.468623  0.017950  0.015186   \n","\n","          7         8         9  ...       891       892       893       894  \\\n","0  0.085337  0.257170  0.265595  ...  0.156270  0.155811  0.196493  0.159470   \n","1  0.033805  0.097025  0.113099  ...  0.140010  0.224248  0.224248  0.189467   \n","2  0.041365  0.048285  0.080519  ...  0.148656  0.229504  0.075861  0.146397   \n","3  0.189635  0.326340  0.233875  ...  0.229211  0.181932  0.119501  0.041688   \n","4  0.009172  0.001096  0.008643  ...  0.184800  0.147886  0.119755  0.087404   \n","5  0.013810  0.007851  0.040798  ...  0.213393  0.138265  0.185955  0.135075   \n","6  0.046705  0.020869  0.055726  ...  0.026252  0.027352  0.052256  0.102832   \n","7  0.168491  0.221830  0.221830  ...  0.215050  0.215050  0.180919  0.167876   \n","8  0.070115  0.259639  0.025288  ...  0.044217  0.045197  0.091030  0.146984   \n","9  0.015980  0.004607  0.022239  ...  0.024768  0.039171  0.035877  0.065767   \n","\n","        895       896       897       898       899               class  \n","0  0.202327  0.202327  0.184796  0.156175  0.202327       saint_bernard  \n","1  0.138448  0.110972  0.153919  0.159000  0.080168        newfoundland  \n","2  0.229504  0.229504  0.229504  0.229504  0.229504       saint_bernard  \n","3  0.054381  0.039874  0.024154  0.031233  0.061346  german_shorthaired  \n","4  0.061873  0.066438  0.050155  0.112934  0.142847  german_shorthaired  \n","5  0.180146  0.187423  0.212892  0.213393  0.202421        newfoundland  \n","6  0.262763  0.262763  0.142727  0.044981  0.030934  german_shorthaired  \n","7  0.131632  0.126436  0.116260  0.188878  0.165014             Siamese  \n","8  0.153986  0.133479  0.074583  0.034886  0.041833             Siamese  \n","9  0.203251  0.114554  0.211534  0.083035  0.072461          Maine_Coon  \n","\n","[10 rows x 901 columns]"],"text/html":["\n","  <div id=\"df-fc99da0b-1c0e-4bba-aba7-3485a27f87e4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>891</th>\n","      <th>892</th>\n","      <th>893</th>\n","      <th>894</th>\n","      <th>895</th>\n","      <th>896</th>\n","      <th>897</th>\n","      <th>898</th>\n","      <th>899</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.192672</td>\n","      <td>0.028051</td>\n","      <td>0.036526</td>\n","      <td>0.150926</td>\n","      <td>0.280795</td>\n","      <td>0.082921</td>\n","      <td>0.036948</td>\n","      <td>0.085337</td>\n","      <td>0.257170</td>\n","      <td>0.265595</td>\n","      <td>...</td>\n","      <td>0.156270</td>\n","      <td>0.155811</td>\n","      <td>0.196493</td>\n","      <td>0.159470</td>\n","      <td>0.202327</td>\n","      <td>0.202327</td>\n","      <td>0.184796</td>\n","      <td>0.156175</td>\n","      <td>0.202327</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.142662</td>\n","      <td>0.123226</td>\n","      <td>0.116038</td>\n","      <td>0.303666</td>\n","      <td>0.303666</td>\n","      <td>0.071292</td>\n","      <td>0.049766</td>\n","      <td>0.033805</td>\n","      <td>0.097025</td>\n","      <td>0.113099</td>\n","      <td>...</td>\n","      <td>0.140010</td>\n","      <td>0.224248</td>\n","      <td>0.224248</td>\n","      <td>0.189467</td>\n","      <td>0.138448</td>\n","      <td>0.110972</td>\n","      <td>0.153919</td>\n","      <td>0.159000</td>\n","      <td>0.080168</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.133335</td>\n","      <td>0.102938</td>\n","      <td>0.108485</td>\n","      <td>0.184473</td>\n","      <td>0.264377</td>\n","      <td>0.130174</td>\n","      <td>0.061767</td>\n","      <td>0.041365</td>\n","      <td>0.048285</td>\n","      <td>0.080519</td>\n","      <td>...</td>\n","      <td>0.148656</td>\n","      <td>0.229504</td>\n","      <td>0.075861</td>\n","      <td>0.146397</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.217431</td>\n","      <td>0.051086</td>\n","      <td>0.106189</td>\n","      <td>0.107343</td>\n","      <td>0.326340</td>\n","      <td>0.217139</td>\n","      <td>0.161545</td>\n","      <td>0.189635</td>\n","      <td>0.326340</td>\n","      <td>0.233875</td>\n","      <td>...</td>\n","      <td>0.229211</td>\n","      <td>0.181932</td>\n","      <td>0.119501</td>\n","      <td>0.041688</td>\n","      <td>0.054381</td>\n","      <td>0.039874</td>\n","      <td>0.024154</td>\n","      <td>0.031233</td>\n","      <td>0.061346</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.008161</td>\n","      <td>0.012362</td>\n","      <td>0.020602</td>\n","      <td>0.033756</td>\n","      <td>0.334871</td>\n","      <td>0.072182</td>\n","      <td>0.015856</td>\n","      <td>0.009172</td>\n","      <td>0.001096</td>\n","      <td>0.008643</td>\n","      <td>...</td>\n","      <td>0.184800</td>\n","      <td>0.147886</td>\n","      <td>0.119755</td>\n","      <td>0.087404</td>\n","      <td>0.061873</td>\n","      <td>0.066438</td>\n","      <td>0.050155</td>\n","      <td>0.112934</td>\n","      <td>0.142847</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.023072</td>\n","      <td>0.008885</td>\n","      <td>0.020361</td>\n","      <td>0.348199</td>\n","      <td>0.348199</td>\n","      <td>0.057047</td>\n","      <td>0.007032</td>\n","      <td>0.013810</td>\n","      <td>0.007851</td>\n","      <td>0.040798</td>\n","      <td>...</td>\n","      <td>0.213393</td>\n","      <td>0.138265</td>\n","      <td>0.185955</td>\n","      <td>0.135075</td>\n","      <td>0.180146</td>\n","      <td>0.187423</td>\n","      <td>0.212892</td>\n","      <td>0.213393</td>\n","      <td>0.202421</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.056318</td>\n","      <td>0.042170</td>\n","      <td>0.102166</td>\n","      <td>0.217575</td>\n","      <td>0.261892</td>\n","      <td>0.261892</td>\n","      <td>0.100534</td>\n","      <td>0.046705</td>\n","      <td>0.020869</td>\n","      <td>0.055726</td>\n","      <td>...</td>\n","      <td>0.026252</td>\n","      <td>0.027352</td>\n","      <td>0.052256</td>\n","      <td>0.102832</td>\n","      <td>0.262763</td>\n","      <td>0.262763</td>\n","      <td>0.142727</td>\n","      <td>0.044981</td>\n","      <td>0.030934</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.221830</td>\n","      <td>0.148585</td>\n","      <td>0.077969</td>\n","      <td>0.059769</td>\n","      <td>0.090290</td>\n","      <td>0.096473</td>\n","      <td>0.096775</td>\n","      <td>0.168491</td>\n","      <td>0.221830</td>\n","      <td>0.221830</td>\n","      <td>...</td>\n","      <td>0.215050</td>\n","      <td>0.215050</td>\n","      <td>0.180919</td>\n","      <td>0.167876</td>\n","      <td>0.131632</td>\n","      <td>0.126436</td>\n","      <td>0.116260</td>\n","      <td>0.188878</td>\n","      <td>0.165014</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.259639</td>\n","      <td>0.223354</td>\n","      <td>0.259639</td>\n","      <td>0.072631</td>\n","      <td>0.165941</td>\n","      <td>0.062421</td>\n","      <td>0.038767</td>\n","      <td>0.070115</td>\n","      <td>0.259639</td>\n","      <td>0.025288</td>\n","      <td>...</td>\n","      <td>0.044217</td>\n","      <td>0.045197</td>\n","      <td>0.091030</td>\n","      <td>0.146984</td>\n","      <td>0.153986</td>\n","      <td>0.133479</td>\n","      <td>0.074583</td>\n","      <td>0.034886</td>\n","      <td>0.041833</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.011779</td>\n","      <td>0.004259</td>\n","      <td>0.010007</td>\n","      <td>0.018802</td>\n","      <td>0.468623</td>\n","      <td>0.017950</td>\n","      <td>0.015186</td>\n","      <td>0.015980</td>\n","      <td>0.004607</td>\n","      <td>0.022239</td>\n","      <td>...</td>\n","      <td>0.024768</td>\n","      <td>0.039171</td>\n","      <td>0.035877</td>\n","      <td>0.065767</td>\n","      <td>0.203251</td>\n","      <td>0.114554</td>\n","      <td>0.211534</td>\n","      <td>0.083035</td>\n","      <td>0.072461</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 901 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc99da0b-1c0e-4bba-aba7-3485a27f87e4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc99da0b-1c0e-4bba-aba7-3485a27f87e4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc99da0b-1c0e-4bba-aba7-3485a27f87e4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["d = 900\n","df_900 = pd.read_csv(path_to_datasets+f\"dataset_normal_d={d}.csv\")\n","df_900.head(10)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1670978263942,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"uJ3l9GO9aS4c"},"outputs":[],"source":["X_900 = df_900[[str(i) for i in range(d)]]\n","y_900 = df_900['class']"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1670978263942,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"zPandlELaS4e","outputId":"8ee6d6b2-c036-489c-d8ae-37bc5e95dedd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.192672  0.028051  0.036526  0.150926  0.280795  0.082921  0.036948   \n","1  0.142662  0.123226  0.116038  0.303666  0.303666  0.071292  0.049766   \n","2  0.133335  0.102938  0.108485  0.184473  0.264377  0.130174  0.061767   \n","3  0.217431  0.051086  0.106189  0.107343  0.326340  0.217139  0.161545   \n","4  0.008161  0.012362  0.020602  0.033756  0.334871  0.072182  0.015856   \n","5  0.023072  0.008885  0.020361  0.348199  0.348199  0.057047  0.007032   \n","6  0.056318  0.042170  0.102166  0.217575  0.261892  0.261892  0.100534   \n","7  0.221830  0.148585  0.077969  0.059769  0.090290  0.096473  0.096775   \n","8  0.259639  0.223354  0.259639  0.072631  0.165941  0.062421  0.038767   \n","9  0.011779  0.004259  0.010007  0.018802  0.468623  0.017950  0.015186   \n","\n","          7         8         9  ...       890       891       892       893  \\\n","0  0.085337  0.257170  0.265595  ...  0.162824  0.156270  0.155811  0.196493   \n","1  0.033805  0.097025  0.113099  ...  0.224248  0.140010  0.224248  0.224248   \n","2  0.041365  0.048285  0.080519  ...  0.229504  0.148656  0.229504  0.075861   \n","3  0.189635  0.326340  0.233875  ...  0.229211  0.229211  0.181932  0.119501   \n","4  0.009172  0.001096  0.008643  ...  0.122051  0.184800  0.147886  0.119755   \n","5  0.013810  0.007851  0.040798  ...  0.213393  0.213393  0.138265  0.185955   \n","6  0.046705  0.020869  0.055726  ...  0.262763  0.026252  0.027352  0.052256   \n","7  0.168491  0.221830  0.221830  ...  0.170303  0.215050  0.215050  0.180919   \n","8  0.070115  0.259639  0.025288  ...  0.035029  0.044217  0.045197  0.091030   \n","9  0.015980  0.004607  0.022239  ...  0.086131  0.024768  0.039171  0.035877   \n","\n","        894       895       896       897       898       899  \n","0  0.159470  0.202327  0.202327  0.184796  0.156175  0.202327  \n","1  0.189467  0.138448  0.110972  0.153919  0.159000  0.080168  \n","2  0.146397  0.229504  0.229504  0.229504  0.229504  0.229504  \n","3  0.041688  0.054381  0.039874  0.024154  0.031233  0.061346  \n","4  0.087404  0.061873  0.066438  0.050155  0.112934  0.142847  \n","5  0.135075  0.180146  0.187423  0.212892  0.213393  0.202421  \n","6  0.102832  0.262763  0.262763  0.142727  0.044981  0.030934  \n","7  0.167876  0.131632  0.126436  0.116260  0.188878  0.165014  \n","8  0.146984  0.153986  0.133479  0.074583  0.034886  0.041833  \n","9  0.065767  0.203251  0.114554  0.211534  0.083035  0.072461  \n","\n","[10 rows x 900 columns]"],"text/html":["\n","  <div id=\"df-06e163a9-39a4-403c-ba34-3ed0d891e027\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>890</th>\n","      <th>891</th>\n","      <th>892</th>\n","      <th>893</th>\n","      <th>894</th>\n","      <th>895</th>\n","      <th>896</th>\n","      <th>897</th>\n","      <th>898</th>\n","      <th>899</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.192672</td>\n","      <td>0.028051</td>\n","      <td>0.036526</td>\n","      <td>0.150926</td>\n","      <td>0.280795</td>\n","      <td>0.082921</td>\n","      <td>0.036948</td>\n","      <td>0.085337</td>\n","      <td>0.257170</td>\n","      <td>0.265595</td>\n","      <td>...</td>\n","      <td>0.162824</td>\n","      <td>0.156270</td>\n","      <td>0.155811</td>\n","      <td>0.196493</td>\n","      <td>0.159470</td>\n","      <td>0.202327</td>\n","      <td>0.202327</td>\n","      <td>0.184796</td>\n","      <td>0.156175</td>\n","      <td>0.202327</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.142662</td>\n","      <td>0.123226</td>\n","      <td>0.116038</td>\n","      <td>0.303666</td>\n","      <td>0.303666</td>\n","      <td>0.071292</td>\n","      <td>0.049766</td>\n","      <td>0.033805</td>\n","      <td>0.097025</td>\n","      <td>0.113099</td>\n","      <td>...</td>\n","      <td>0.224248</td>\n","      <td>0.140010</td>\n","      <td>0.224248</td>\n","      <td>0.224248</td>\n","      <td>0.189467</td>\n","      <td>0.138448</td>\n","      <td>0.110972</td>\n","      <td>0.153919</td>\n","      <td>0.159000</td>\n","      <td>0.080168</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.133335</td>\n","      <td>0.102938</td>\n","      <td>0.108485</td>\n","      <td>0.184473</td>\n","      <td>0.264377</td>\n","      <td>0.130174</td>\n","      <td>0.061767</td>\n","      <td>0.041365</td>\n","      <td>0.048285</td>\n","      <td>0.080519</td>\n","      <td>...</td>\n","      <td>0.229504</td>\n","      <td>0.148656</td>\n","      <td>0.229504</td>\n","      <td>0.075861</td>\n","      <td>0.146397</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","      <td>0.229504</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.217431</td>\n","      <td>0.051086</td>\n","      <td>0.106189</td>\n","      <td>0.107343</td>\n","      <td>0.326340</td>\n","      <td>0.217139</td>\n","      <td>0.161545</td>\n","      <td>0.189635</td>\n","      <td>0.326340</td>\n","      <td>0.233875</td>\n","      <td>...</td>\n","      <td>0.229211</td>\n","      <td>0.229211</td>\n","      <td>0.181932</td>\n","      <td>0.119501</td>\n","      <td>0.041688</td>\n","      <td>0.054381</td>\n","      <td>0.039874</td>\n","      <td>0.024154</td>\n","      <td>0.031233</td>\n","      <td>0.061346</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.008161</td>\n","      <td>0.012362</td>\n","      <td>0.020602</td>\n","      <td>0.033756</td>\n","      <td>0.334871</td>\n","      <td>0.072182</td>\n","      <td>0.015856</td>\n","      <td>0.009172</td>\n","      <td>0.001096</td>\n","      <td>0.008643</td>\n","      <td>...</td>\n","      <td>0.122051</td>\n","      <td>0.184800</td>\n","      <td>0.147886</td>\n","      <td>0.119755</td>\n","      <td>0.087404</td>\n","      <td>0.061873</td>\n","      <td>0.066438</td>\n","      <td>0.050155</td>\n","      <td>0.112934</td>\n","      <td>0.142847</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.023072</td>\n","      <td>0.008885</td>\n","      <td>0.020361</td>\n","      <td>0.348199</td>\n","      <td>0.348199</td>\n","      <td>0.057047</td>\n","      <td>0.007032</td>\n","      <td>0.013810</td>\n","      <td>0.007851</td>\n","      <td>0.040798</td>\n","      <td>...</td>\n","      <td>0.213393</td>\n","      <td>0.213393</td>\n","      <td>0.138265</td>\n","      <td>0.185955</td>\n","      <td>0.135075</td>\n","      <td>0.180146</td>\n","      <td>0.187423</td>\n","      <td>0.212892</td>\n","      <td>0.213393</td>\n","      <td>0.202421</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.056318</td>\n","      <td>0.042170</td>\n","      <td>0.102166</td>\n","      <td>0.217575</td>\n","      <td>0.261892</td>\n","      <td>0.261892</td>\n","      <td>0.100534</td>\n","      <td>0.046705</td>\n","      <td>0.020869</td>\n","      <td>0.055726</td>\n","      <td>...</td>\n","      <td>0.262763</td>\n","      <td>0.026252</td>\n","      <td>0.027352</td>\n","      <td>0.052256</td>\n","      <td>0.102832</td>\n","      <td>0.262763</td>\n","      <td>0.262763</td>\n","      <td>0.142727</td>\n","      <td>0.044981</td>\n","      <td>0.030934</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.221830</td>\n","      <td>0.148585</td>\n","      <td>0.077969</td>\n","      <td>0.059769</td>\n","      <td>0.090290</td>\n","      <td>0.096473</td>\n","      <td>0.096775</td>\n","      <td>0.168491</td>\n","      <td>0.221830</td>\n","      <td>0.221830</td>\n","      <td>...</td>\n","      <td>0.170303</td>\n","      <td>0.215050</td>\n","      <td>0.215050</td>\n","      <td>0.180919</td>\n","      <td>0.167876</td>\n","      <td>0.131632</td>\n","      <td>0.126436</td>\n","      <td>0.116260</td>\n","      <td>0.188878</td>\n","      <td>0.165014</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.259639</td>\n","      <td>0.223354</td>\n","      <td>0.259639</td>\n","      <td>0.072631</td>\n","      <td>0.165941</td>\n","      <td>0.062421</td>\n","      <td>0.038767</td>\n","      <td>0.070115</td>\n","      <td>0.259639</td>\n","      <td>0.025288</td>\n","      <td>...</td>\n","      <td>0.035029</td>\n","      <td>0.044217</td>\n","      <td>0.045197</td>\n","      <td>0.091030</td>\n","      <td>0.146984</td>\n","      <td>0.153986</td>\n","      <td>0.133479</td>\n","      <td>0.074583</td>\n","      <td>0.034886</td>\n","      <td>0.041833</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.011779</td>\n","      <td>0.004259</td>\n","      <td>0.010007</td>\n","      <td>0.018802</td>\n","      <td>0.468623</td>\n","      <td>0.017950</td>\n","      <td>0.015186</td>\n","      <td>0.015980</td>\n","      <td>0.004607</td>\n","      <td>0.022239</td>\n","      <td>...</td>\n","      <td>0.086131</td>\n","      <td>0.024768</td>\n","      <td>0.039171</td>\n","      <td>0.035877</td>\n","      <td>0.065767</td>\n","      <td>0.203251</td>\n","      <td>0.114554</td>\n","      <td>0.211534</td>\n","      <td>0.083035</td>\n","      <td>0.072461</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 900 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06e163a9-39a4-403c-ba34-3ed0d891e027')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-06e163a9-39a4-403c-ba34-3ed0d891e027 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-06e163a9-39a4-403c-ba34-3ed0d891e027');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["X_900.head(10)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1670978263943,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"Wp-dVH_6aS4g","outputId":"6120d61a-f6ea-490d-89ea-35020370d615"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         saint_bernard\n","1          newfoundland\n","2         saint_bernard\n","3    german_shorthaired\n","4    german_shorthaired\n","5          newfoundland\n","6    german_shorthaired\n","7               Siamese\n","8               Siamese\n","9            Maine_Coon\n","Name: class, dtype: object"]},"metadata":{},"execution_count":14}],"source":["y_900.head(10)"]},{"cell_type":"markdown","metadata":{"id":"9qGCEYT38VHG"},"source":["\n","## PCA dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1670978264480,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"tqXs2CUr_fzi","outputId":"a6ede30b-fc9d-4cbd-a838-5eb7aac9cd58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0          1          2         3          4          5         6  \\\n","0  -2.380297  -6.699200  -1.279775 -3.351839  -3.153540  -1.581257 -2.336414   \n","1 -12.872690   0.867347  -7.311219 -2.723342   7.512874   4.858072 -5.430090   \n","2  19.803550  13.238198  13.707408 -6.911591   1.891338  -5.305213  3.740378   \n","3  -7.288759  -4.973596   4.780992 -6.902126   2.093638   0.482812 -5.864648   \n","4  -3.112963   5.895254  -3.189320 -0.559430   3.115830  18.027040 -1.415460   \n","5  -9.746863  11.490945   8.546451 -3.568241  11.093349  11.211527 -0.996962   \n","6   7.460773   5.929461   8.912441 -2.942329  11.985439  -2.766329 -3.893858   \n","7   6.210230   1.656566  -1.036083 -4.342239 -13.864614  -6.529270 -1.515298   \n","8   4.863115  -9.843244  -3.603921  4.353471  -5.785158   3.904291  0.790688   \n","9  -3.465979 -10.781202   1.252026 -5.862053   0.196873   3.088654 -3.769342   \n","\n","          7         8         9  ...       450       451       452       453  \\\n","0 -1.796308  1.184499  6.119493  ... -0.533290 -0.293528  0.823915 -0.126073   \n","1 -3.116403  5.055318  2.609234  ...  0.034227  0.040574  0.431669  0.401022   \n","2 -4.750921  7.602592 -5.477753  ...  0.986000 -0.010172 -0.585129  0.519787   \n","3  2.501886  0.341229  0.032766  ...  0.680068  0.147463  0.001999 -0.573872   \n","4  5.475730  1.363855  0.777862  ... -0.481629 -0.401537 -0.017111 -0.454708   \n","5  1.790621 -3.837276 -5.567937  ...  0.111946 -0.454768 -0.289299 -0.570193   \n","6 -0.534358  4.567333  4.389766  ...  0.185821 -1.043474 -0.056761  0.334469   \n","7 -4.810006  3.916744 -2.192208  ... -0.141879  0.274773 -0.731951 -0.495013   \n","8  0.041945  7.587338 -3.230698  ... -0.256992 -0.505148  0.409582  1.279912   \n","9  4.683802  1.577823  2.359722  ...  0.244139 -0.707439  0.126319 -0.629447   \n","\n","        454       455       456       457       458               class  \n","0 -0.540484 -0.997431  1.111734  0.151672 -0.032959  german_shorthaired  \n","1  0.753521  0.296330  0.330976 -0.664927  0.234228          Maine_Coon  \n","2  0.409538 -0.546216  0.011639  0.114498  0.100038             Siamese  \n","3  0.550128  0.616860 -0.040501  0.528254 -0.924901        newfoundland  \n","4  0.248465  0.261943  0.060084  0.371404  0.131689       saint_bernard  \n","5 -0.061763 -0.634777  0.968670  0.815620 -0.011793        newfoundland  \n","6 -0.296624  1.039284  0.177596 -0.450310 -0.097540          Maine_Coon  \n","7  0.868642  0.225305  0.322655 -0.465061 -0.558365             Siamese  \n","8  0.037469  0.551778  0.000182 -0.247022  0.459312       saint_bernard  \n","9  0.737886 -0.319548 -0.358627 -0.594520  0.372839        newfoundland  \n","\n","[10 rows x 460 columns]"],"text/html":["\n","  <div id=\"df-7ce40fbb-60a0-48f6-b591-804ecac7edb0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>450</th>\n","      <th>451</th>\n","      <th>452</th>\n","      <th>453</th>\n","      <th>454</th>\n","      <th>455</th>\n","      <th>456</th>\n","      <th>457</th>\n","      <th>458</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-2.380297</td>\n","      <td>-6.699200</td>\n","      <td>-1.279775</td>\n","      <td>-3.351839</td>\n","      <td>-3.153540</td>\n","      <td>-1.581257</td>\n","      <td>-2.336414</td>\n","      <td>-1.796308</td>\n","      <td>1.184499</td>\n","      <td>6.119493</td>\n","      <td>...</td>\n","      <td>-0.533290</td>\n","      <td>-0.293528</td>\n","      <td>0.823915</td>\n","      <td>-0.126073</td>\n","      <td>-0.540484</td>\n","      <td>-0.997431</td>\n","      <td>1.111734</td>\n","      <td>0.151672</td>\n","      <td>-0.032959</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-12.872690</td>\n","      <td>0.867347</td>\n","      <td>-7.311219</td>\n","      <td>-2.723342</td>\n","      <td>7.512874</td>\n","      <td>4.858072</td>\n","      <td>-5.430090</td>\n","      <td>-3.116403</td>\n","      <td>5.055318</td>\n","      <td>2.609234</td>\n","      <td>...</td>\n","      <td>0.034227</td>\n","      <td>0.040574</td>\n","      <td>0.431669</td>\n","      <td>0.401022</td>\n","      <td>0.753521</td>\n","      <td>0.296330</td>\n","      <td>0.330976</td>\n","      <td>-0.664927</td>\n","      <td>0.234228</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.803550</td>\n","      <td>13.238198</td>\n","      <td>13.707408</td>\n","      <td>-6.911591</td>\n","      <td>1.891338</td>\n","      <td>-5.305213</td>\n","      <td>3.740378</td>\n","      <td>-4.750921</td>\n","      <td>7.602592</td>\n","      <td>-5.477753</td>\n","      <td>...</td>\n","      <td>0.986000</td>\n","      <td>-0.010172</td>\n","      <td>-0.585129</td>\n","      <td>0.519787</td>\n","      <td>0.409538</td>\n","      <td>-0.546216</td>\n","      <td>0.011639</td>\n","      <td>0.114498</td>\n","      <td>0.100038</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-7.288759</td>\n","      <td>-4.973596</td>\n","      <td>4.780992</td>\n","      <td>-6.902126</td>\n","      <td>2.093638</td>\n","      <td>0.482812</td>\n","      <td>-5.864648</td>\n","      <td>2.501886</td>\n","      <td>0.341229</td>\n","      <td>0.032766</td>\n","      <td>...</td>\n","      <td>0.680068</td>\n","      <td>0.147463</td>\n","      <td>0.001999</td>\n","      <td>-0.573872</td>\n","      <td>0.550128</td>\n","      <td>0.616860</td>\n","      <td>-0.040501</td>\n","      <td>0.528254</td>\n","      <td>-0.924901</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-3.112963</td>\n","      <td>5.895254</td>\n","      <td>-3.189320</td>\n","      <td>-0.559430</td>\n","      <td>3.115830</td>\n","      <td>18.027040</td>\n","      <td>-1.415460</td>\n","      <td>5.475730</td>\n","      <td>1.363855</td>\n","      <td>0.777862</td>\n","      <td>...</td>\n","      <td>-0.481629</td>\n","      <td>-0.401537</td>\n","      <td>-0.017111</td>\n","      <td>-0.454708</td>\n","      <td>0.248465</td>\n","      <td>0.261943</td>\n","      <td>0.060084</td>\n","      <td>0.371404</td>\n","      <td>0.131689</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-9.746863</td>\n","      <td>11.490945</td>\n","      <td>8.546451</td>\n","      <td>-3.568241</td>\n","      <td>11.093349</td>\n","      <td>11.211527</td>\n","      <td>-0.996962</td>\n","      <td>1.790621</td>\n","      <td>-3.837276</td>\n","      <td>-5.567937</td>\n","      <td>...</td>\n","      <td>0.111946</td>\n","      <td>-0.454768</td>\n","      <td>-0.289299</td>\n","      <td>-0.570193</td>\n","      <td>-0.061763</td>\n","      <td>-0.634777</td>\n","      <td>0.968670</td>\n","      <td>0.815620</td>\n","      <td>-0.011793</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7.460773</td>\n","      <td>5.929461</td>\n","      <td>8.912441</td>\n","      <td>-2.942329</td>\n","      <td>11.985439</td>\n","      <td>-2.766329</td>\n","      <td>-3.893858</td>\n","      <td>-0.534358</td>\n","      <td>4.567333</td>\n","      <td>4.389766</td>\n","      <td>...</td>\n","      <td>0.185821</td>\n","      <td>-1.043474</td>\n","      <td>-0.056761</td>\n","      <td>0.334469</td>\n","      <td>-0.296624</td>\n","      <td>1.039284</td>\n","      <td>0.177596</td>\n","      <td>-0.450310</td>\n","      <td>-0.097540</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.210230</td>\n","      <td>1.656566</td>\n","      <td>-1.036083</td>\n","      <td>-4.342239</td>\n","      <td>-13.864614</td>\n","      <td>-6.529270</td>\n","      <td>-1.515298</td>\n","      <td>-4.810006</td>\n","      <td>3.916744</td>\n","      <td>-2.192208</td>\n","      <td>...</td>\n","      <td>-0.141879</td>\n","      <td>0.274773</td>\n","      <td>-0.731951</td>\n","      <td>-0.495013</td>\n","      <td>0.868642</td>\n","      <td>0.225305</td>\n","      <td>0.322655</td>\n","      <td>-0.465061</td>\n","      <td>-0.558365</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.863115</td>\n","      <td>-9.843244</td>\n","      <td>-3.603921</td>\n","      <td>4.353471</td>\n","      <td>-5.785158</td>\n","      <td>3.904291</td>\n","      <td>0.790688</td>\n","      <td>0.041945</td>\n","      <td>7.587338</td>\n","      <td>-3.230698</td>\n","      <td>...</td>\n","      <td>-0.256992</td>\n","      <td>-0.505148</td>\n","      <td>0.409582</td>\n","      <td>1.279912</td>\n","      <td>0.037469</td>\n","      <td>0.551778</td>\n","      <td>0.000182</td>\n","      <td>-0.247022</td>\n","      <td>0.459312</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>-3.465979</td>\n","      <td>-10.781202</td>\n","      <td>1.252026</td>\n","      <td>-5.862053</td>\n","      <td>0.196873</td>\n","      <td>3.088654</td>\n","      <td>-3.769342</td>\n","      <td>4.683802</td>\n","      <td>1.577823</td>\n","      <td>2.359722</td>\n","      <td>...</td>\n","      <td>0.244139</td>\n","      <td>-0.707439</td>\n","      <td>0.126319</td>\n","      <td>-0.629447</td>\n","      <td>0.737886</td>\n","      <td>-0.319548</td>\n","      <td>-0.358627</td>\n","      <td>-0.594520</td>\n","      <td>0.372839</td>\n","      <td>newfoundland</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 460 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce40fbb-60a0-48f6-b591-804ecac7edb0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7ce40fbb-60a0-48f6-b591-804ecac7edb0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7ce40fbb-60a0-48f6-b591-804ecac7edb0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["d = 459\n","df_pca = pd.read_csv(path_to_datasets+f\"dataset_pca_d={d}.csv\")\n","df_pca.head(10)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1670978264482,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"wb-PJYKUx8v-"},"outputs":[],"source":["X_pca = df_pca[[str(i) for i in range(d)]]\n","y_pca = df_pca['class']"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1670978264483,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"icaaS7T2yIXH","outputId":"dfb93e8f-fe86-4936-fd25-1c646ed7d48b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0          1          2         3          4          5         6  \\\n","0  -2.380297  -6.699200  -1.279775 -3.351839  -3.153540  -1.581257 -2.336414   \n","1 -12.872690   0.867347  -7.311219 -2.723342   7.512874   4.858072 -5.430090   \n","2  19.803550  13.238198  13.707408 -6.911591   1.891338  -5.305213  3.740378   \n","3  -7.288759  -4.973596   4.780992 -6.902126   2.093638   0.482812 -5.864648   \n","4  -3.112963   5.895254  -3.189320 -0.559430   3.115830  18.027040 -1.415460   \n","5  -9.746863  11.490945   8.546451 -3.568241  11.093349  11.211527 -0.996962   \n","6   7.460773   5.929461   8.912441 -2.942329  11.985439  -2.766329 -3.893858   \n","7   6.210230   1.656566  -1.036083 -4.342239 -13.864614  -6.529270 -1.515298   \n","8   4.863115  -9.843244  -3.603921  4.353471  -5.785158   3.904291  0.790688   \n","9  -3.465979 -10.781202   1.252026 -5.862053   0.196873   3.088654 -3.769342   \n","\n","          7         8         9  ...       449       450       451       452  \\\n","0 -1.796308  1.184499  6.119493  ...  0.663052 -0.533290 -0.293528  0.823915   \n","1 -3.116403  5.055318  2.609234  ... -0.529673  0.034227  0.040574  0.431669   \n","2 -4.750921  7.602592 -5.477753  ... -0.245385  0.986000 -0.010172 -0.585129   \n","3  2.501886  0.341229  0.032766  ...  0.902008  0.680068  0.147463  0.001999   \n","4  5.475730  1.363855  0.777862  ...  0.219799 -0.481629 -0.401537 -0.017111   \n","5  1.790621 -3.837276 -5.567937  ... -0.195720  0.111946 -0.454768 -0.289299   \n","6 -0.534358  4.567333  4.389766  ...  0.577769  0.185821 -1.043474 -0.056761   \n","7 -4.810006  3.916744 -2.192208  ... -0.374555 -0.141879  0.274773 -0.731951   \n","8  0.041945  7.587338 -3.230698  ... -0.410371 -0.256992 -0.505148  0.409582   \n","9  4.683802  1.577823  2.359722  ...  0.115154  0.244139 -0.707439  0.126319   \n","\n","        453       454       455       456       457       458  \n","0 -0.126073 -0.540484 -0.997431  1.111734  0.151672 -0.032959  \n","1  0.401022  0.753521  0.296330  0.330976 -0.664927  0.234228  \n","2  0.519787  0.409538 -0.546216  0.011639  0.114498  0.100038  \n","3 -0.573872  0.550128  0.616860 -0.040501  0.528254 -0.924901  \n","4 -0.454708  0.248465  0.261943  0.060084  0.371404  0.131689  \n","5 -0.570193 -0.061763 -0.634777  0.968670  0.815620 -0.011793  \n","6  0.334469 -0.296624  1.039284  0.177596 -0.450310 -0.097540  \n","7 -0.495013  0.868642  0.225305  0.322655 -0.465061 -0.558365  \n","8  1.279912  0.037469  0.551778  0.000182 -0.247022  0.459312  \n","9 -0.629447  0.737886 -0.319548 -0.358627 -0.594520  0.372839  \n","\n","[10 rows x 459 columns]"],"text/html":["\n","  <div id=\"df-cbf8aec5-66f1-4cf3-b3ff-74b5ddd37ef4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>449</th>\n","      <th>450</th>\n","      <th>451</th>\n","      <th>452</th>\n","      <th>453</th>\n","      <th>454</th>\n","      <th>455</th>\n","      <th>456</th>\n","      <th>457</th>\n","      <th>458</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-2.380297</td>\n","      <td>-6.699200</td>\n","      <td>-1.279775</td>\n","      <td>-3.351839</td>\n","      <td>-3.153540</td>\n","      <td>-1.581257</td>\n","      <td>-2.336414</td>\n","      <td>-1.796308</td>\n","      <td>1.184499</td>\n","      <td>6.119493</td>\n","      <td>...</td>\n","      <td>0.663052</td>\n","      <td>-0.533290</td>\n","      <td>-0.293528</td>\n","      <td>0.823915</td>\n","      <td>-0.126073</td>\n","      <td>-0.540484</td>\n","      <td>-0.997431</td>\n","      <td>1.111734</td>\n","      <td>0.151672</td>\n","      <td>-0.032959</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-12.872690</td>\n","      <td>0.867347</td>\n","      <td>-7.311219</td>\n","      <td>-2.723342</td>\n","      <td>7.512874</td>\n","      <td>4.858072</td>\n","      <td>-5.430090</td>\n","      <td>-3.116403</td>\n","      <td>5.055318</td>\n","      <td>2.609234</td>\n","      <td>...</td>\n","      <td>-0.529673</td>\n","      <td>0.034227</td>\n","      <td>0.040574</td>\n","      <td>0.431669</td>\n","      <td>0.401022</td>\n","      <td>0.753521</td>\n","      <td>0.296330</td>\n","      <td>0.330976</td>\n","      <td>-0.664927</td>\n","      <td>0.234228</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.803550</td>\n","      <td>13.238198</td>\n","      <td>13.707408</td>\n","      <td>-6.911591</td>\n","      <td>1.891338</td>\n","      <td>-5.305213</td>\n","      <td>3.740378</td>\n","      <td>-4.750921</td>\n","      <td>7.602592</td>\n","      <td>-5.477753</td>\n","      <td>...</td>\n","      <td>-0.245385</td>\n","      <td>0.986000</td>\n","      <td>-0.010172</td>\n","      <td>-0.585129</td>\n","      <td>0.519787</td>\n","      <td>0.409538</td>\n","      <td>-0.546216</td>\n","      <td>0.011639</td>\n","      <td>0.114498</td>\n","      <td>0.100038</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-7.288759</td>\n","      <td>-4.973596</td>\n","      <td>4.780992</td>\n","      <td>-6.902126</td>\n","      <td>2.093638</td>\n","      <td>0.482812</td>\n","      <td>-5.864648</td>\n","      <td>2.501886</td>\n","      <td>0.341229</td>\n","      <td>0.032766</td>\n","      <td>...</td>\n","      <td>0.902008</td>\n","      <td>0.680068</td>\n","      <td>0.147463</td>\n","      <td>0.001999</td>\n","      <td>-0.573872</td>\n","      <td>0.550128</td>\n","      <td>0.616860</td>\n","      <td>-0.040501</td>\n","      <td>0.528254</td>\n","      <td>-0.924901</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-3.112963</td>\n","      <td>5.895254</td>\n","      <td>-3.189320</td>\n","      <td>-0.559430</td>\n","      <td>3.115830</td>\n","      <td>18.027040</td>\n","      <td>-1.415460</td>\n","      <td>5.475730</td>\n","      <td>1.363855</td>\n","      <td>0.777862</td>\n","      <td>...</td>\n","      <td>0.219799</td>\n","      <td>-0.481629</td>\n","      <td>-0.401537</td>\n","      <td>-0.017111</td>\n","      <td>-0.454708</td>\n","      <td>0.248465</td>\n","      <td>0.261943</td>\n","      <td>0.060084</td>\n","      <td>0.371404</td>\n","      <td>0.131689</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-9.746863</td>\n","      <td>11.490945</td>\n","      <td>8.546451</td>\n","      <td>-3.568241</td>\n","      <td>11.093349</td>\n","      <td>11.211527</td>\n","      <td>-0.996962</td>\n","      <td>1.790621</td>\n","      <td>-3.837276</td>\n","      <td>-5.567937</td>\n","      <td>...</td>\n","      <td>-0.195720</td>\n","      <td>0.111946</td>\n","      <td>-0.454768</td>\n","      <td>-0.289299</td>\n","      <td>-0.570193</td>\n","      <td>-0.061763</td>\n","      <td>-0.634777</td>\n","      <td>0.968670</td>\n","      <td>0.815620</td>\n","      <td>-0.011793</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7.460773</td>\n","      <td>5.929461</td>\n","      <td>8.912441</td>\n","      <td>-2.942329</td>\n","      <td>11.985439</td>\n","      <td>-2.766329</td>\n","      <td>-3.893858</td>\n","      <td>-0.534358</td>\n","      <td>4.567333</td>\n","      <td>4.389766</td>\n","      <td>...</td>\n","      <td>0.577769</td>\n","      <td>0.185821</td>\n","      <td>-1.043474</td>\n","      <td>-0.056761</td>\n","      <td>0.334469</td>\n","      <td>-0.296624</td>\n","      <td>1.039284</td>\n","      <td>0.177596</td>\n","      <td>-0.450310</td>\n","      <td>-0.097540</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.210230</td>\n","      <td>1.656566</td>\n","      <td>-1.036083</td>\n","      <td>-4.342239</td>\n","      <td>-13.864614</td>\n","      <td>-6.529270</td>\n","      <td>-1.515298</td>\n","      <td>-4.810006</td>\n","      <td>3.916744</td>\n","      <td>-2.192208</td>\n","      <td>...</td>\n","      <td>-0.374555</td>\n","      <td>-0.141879</td>\n","      <td>0.274773</td>\n","      <td>-0.731951</td>\n","      <td>-0.495013</td>\n","      <td>0.868642</td>\n","      <td>0.225305</td>\n","      <td>0.322655</td>\n","      <td>-0.465061</td>\n","      <td>-0.558365</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.863115</td>\n","      <td>-9.843244</td>\n","      <td>-3.603921</td>\n","      <td>4.353471</td>\n","      <td>-5.785158</td>\n","      <td>3.904291</td>\n","      <td>0.790688</td>\n","      <td>0.041945</td>\n","      <td>7.587338</td>\n","      <td>-3.230698</td>\n","      <td>...</td>\n","      <td>-0.410371</td>\n","      <td>-0.256992</td>\n","      <td>-0.505148</td>\n","      <td>0.409582</td>\n","      <td>1.279912</td>\n","      <td>0.037469</td>\n","      <td>0.551778</td>\n","      <td>0.000182</td>\n","      <td>-0.247022</td>\n","      <td>0.459312</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>-3.465979</td>\n","      <td>-10.781202</td>\n","      <td>1.252026</td>\n","      <td>-5.862053</td>\n","      <td>0.196873</td>\n","      <td>3.088654</td>\n","      <td>-3.769342</td>\n","      <td>4.683802</td>\n","      <td>1.577823</td>\n","      <td>2.359722</td>\n","      <td>...</td>\n","      <td>0.115154</td>\n","      <td>0.244139</td>\n","      <td>-0.707439</td>\n","      <td>0.126319</td>\n","      <td>-0.629447</td>\n","      <td>0.737886</td>\n","      <td>-0.319548</td>\n","      <td>-0.358627</td>\n","      <td>-0.594520</td>\n","      <td>0.372839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 459 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf8aec5-66f1-4cf3-b3ff-74b5ddd37ef4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cbf8aec5-66f1-4cf3-b3ff-74b5ddd37ef4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cbf8aec5-66f1-4cf3-b3ff-74b5ddd37ef4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["X_pca.head(10)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1670978264484,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"Y9MENKf7yIMI","outputId":"1b1e16c8-3f15-485a-c839-4f7087041e10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    german_shorthaired\n","1            Maine_Coon\n","2               Siamese\n","3          newfoundland\n","4         saint_bernard\n","5          newfoundland\n","6            Maine_Coon\n","7               Siamese\n","8         saint_bernard\n","9          newfoundland\n","Name: class, dtype: object"]},"metadata":{},"execution_count":18}],"source":["y_pca.head(10)"]},{"cell_type":"markdown","metadata":{"id":"AXosnO4h8ZtX"},"source":["## Correlation dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1670978264484,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"-9qADVNt_T-R","outputId":"c14ebe26-fb40-4652-a388-ffddd9001ead"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.084298  0.055577  0.052653  0.051070  0.100116  0.111726  0.085606   \n","1  0.240130  0.099940  0.107868  0.240130  0.240130  0.240130  0.085054   \n","2  0.296857  0.296857  0.192027  0.118093  0.144822  0.078502  0.067119   \n","3  0.222998  0.140840  0.159199  0.105568  0.190843  0.129682  0.163091   \n","4  0.278233  0.028802  0.004027  0.006154  0.017805  0.008525  0.007660   \n","5  0.252442  0.067413  0.020861  0.026860  0.137779  0.071512  0.024365   \n","6  0.225421  0.260662  0.122048  0.041961  0.075550  0.013764  0.038639   \n","7  0.042428  0.012829  0.051054  0.138152  0.297832  0.094548  0.018066   \n","8  0.218417  0.184951  0.218417  0.176171  0.218417  0.148506  0.122361   \n","9  0.224950  0.184881  0.155280  0.212940  0.133371  0.052802  0.054540   \n","\n","          7         8         9  ...       531       532       533       534  \\\n","0  0.071323  0.131749  0.280054  ...  0.112864  0.186781  0.167077  0.123062   \n","1  0.138299  0.205619  0.086468  ...  0.108184  0.248859  0.108594  0.101801   \n","2  0.102928  0.073403  0.086981  ...  0.021128  0.077877  0.023129  0.057161   \n","3  0.222998  0.222998  0.093282  ...  0.153770  0.185352  0.144374  0.130847   \n","4  0.049038  0.258007  0.034772  ...  0.195922  0.248447  0.231704  0.096816   \n","5  0.047084  0.380612  0.021658  ...  0.172557  0.215076  0.148538  0.158630   \n","6  0.025091  0.262798  0.262798  ...  0.034232  0.026674  0.014406  0.013655   \n","7  0.018478  0.024748  0.003434  ...  0.050333  0.102495  0.069838  0.082066   \n","8  0.079024  0.166223  0.144994  ...  0.135554  0.205706  0.132222  0.136953   \n","9  0.094103  0.210799  0.161341  ...  0.105875  0.148467  0.144005  0.238637   \n","\n","        535       536       537       538       539               class  \n","0  0.206317  0.214587  0.204777  0.210161  0.126280  german_shorthaired  \n","1  0.058171  0.118594  0.088637  0.110307  0.078088          Maine_Coon  \n","2  0.080489  0.364878  0.282017  0.133116  0.154003             Siamese  \n","3  0.150475  0.211966  0.232555  0.185272  0.211561        newfoundland  \n","4  0.054017  0.185490  0.059698  0.134580  0.248447       saint_bernard  \n","5  0.189096  0.215076  0.194341  0.147962  0.211813        newfoundland  \n","6  0.055924  0.307993  0.339604  0.122119  0.033844          Maine_Coon  \n","7  0.166017  0.273593  0.182716  0.119556  0.125424             Siamese  \n","8  0.088043  0.178162  0.127782  0.193361  0.196591       saint_bernard  \n","9  0.238637  0.238637  0.091228  0.066691  0.124647        newfoundland  \n","\n","[10 rows x 541 columns]"],"text/html":["\n","  <div id=\"df-b2890ab7-49ac-4f37-9f61-8af958619d60\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>531</th>\n","      <th>532</th>\n","      <th>533</th>\n","      <th>534</th>\n","      <th>535</th>\n","      <th>536</th>\n","      <th>537</th>\n","      <th>538</th>\n","      <th>539</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.084298</td>\n","      <td>0.055577</td>\n","      <td>0.052653</td>\n","      <td>0.051070</td>\n","      <td>0.100116</td>\n","      <td>0.111726</td>\n","      <td>0.085606</td>\n","      <td>0.071323</td>\n","      <td>0.131749</td>\n","      <td>0.280054</td>\n","      <td>...</td>\n","      <td>0.112864</td>\n","      <td>0.186781</td>\n","      <td>0.167077</td>\n","      <td>0.123062</td>\n","      <td>0.206317</td>\n","      <td>0.214587</td>\n","      <td>0.204777</td>\n","      <td>0.210161</td>\n","      <td>0.126280</td>\n","      <td>german_shorthaired</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.240130</td>\n","      <td>0.099940</td>\n","      <td>0.107868</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.085054</td>\n","      <td>0.138299</td>\n","      <td>0.205619</td>\n","      <td>0.086468</td>\n","      <td>...</td>\n","      <td>0.108184</td>\n","      <td>0.248859</td>\n","      <td>0.108594</td>\n","      <td>0.101801</td>\n","      <td>0.058171</td>\n","      <td>0.118594</td>\n","      <td>0.088637</td>\n","      <td>0.110307</td>\n","      <td>0.078088</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.296857</td>\n","      <td>0.296857</td>\n","      <td>0.192027</td>\n","      <td>0.118093</td>\n","      <td>0.144822</td>\n","      <td>0.078502</td>\n","      <td>0.067119</td>\n","      <td>0.102928</td>\n","      <td>0.073403</td>\n","      <td>0.086981</td>\n","      <td>...</td>\n","      <td>0.021128</td>\n","      <td>0.077877</td>\n","      <td>0.023129</td>\n","      <td>0.057161</td>\n","      <td>0.080489</td>\n","      <td>0.364878</td>\n","      <td>0.282017</td>\n","      <td>0.133116</td>\n","      <td>0.154003</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.222998</td>\n","      <td>0.140840</td>\n","      <td>0.159199</td>\n","      <td>0.105568</td>\n","      <td>0.190843</td>\n","      <td>0.129682</td>\n","      <td>0.163091</td>\n","      <td>0.222998</td>\n","      <td>0.222998</td>\n","      <td>0.093282</td>\n","      <td>...</td>\n","      <td>0.153770</td>\n","      <td>0.185352</td>\n","      <td>0.144374</td>\n","      <td>0.130847</td>\n","      <td>0.150475</td>\n","      <td>0.211966</td>\n","      <td>0.232555</td>\n","      <td>0.185272</td>\n","      <td>0.211561</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.278233</td>\n","      <td>0.028802</td>\n","      <td>0.004027</td>\n","      <td>0.006154</td>\n","      <td>0.017805</td>\n","      <td>0.008525</td>\n","      <td>0.007660</td>\n","      <td>0.049038</td>\n","      <td>0.258007</td>\n","      <td>0.034772</td>\n","      <td>...</td>\n","      <td>0.195922</td>\n","      <td>0.248447</td>\n","      <td>0.231704</td>\n","      <td>0.096816</td>\n","      <td>0.054017</td>\n","      <td>0.185490</td>\n","      <td>0.059698</td>\n","      <td>0.134580</td>\n","      <td>0.248447</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.252442</td>\n","      <td>0.067413</td>\n","      <td>0.020861</td>\n","      <td>0.026860</td>\n","      <td>0.137779</td>\n","      <td>0.071512</td>\n","      <td>0.024365</td>\n","      <td>0.047084</td>\n","      <td>0.380612</td>\n","      <td>0.021658</td>\n","      <td>...</td>\n","      <td>0.172557</td>\n","      <td>0.215076</td>\n","      <td>0.148538</td>\n","      <td>0.158630</td>\n","      <td>0.189096</td>\n","      <td>0.215076</td>\n","      <td>0.194341</td>\n","      <td>0.147962</td>\n","      <td>0.211813</td>\n","      <td>newfoundland</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.225421</td>\n","      <td>0.260662</td>\n","      <td>0.122048</td>\n","      <td>0.041961</td>\n","      <td>0.075550</td>\n","      <td>0.013764</td>\n","      <td>0.038639</td>\n","      <td>0.025091</td>\n","      <td>0.262798</td>\n","      <td>0.262798</td>\n","      <td>...</td>\n","      <td>0.034232</td>\n","      <td>0.026674</td>\n","      <td>0.014406</td>\n","      <td>0.013655</td>\n","      <td>0.055924</td>\n","      <td>0.307993</td>\n","      <td>0.339604</td>\n","      <td>0.122119</td>\n","      <td>0.033844</td>\n","      <td>Maine_Coon</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.042428</td>\n","      <td>0.012829</td>\n","      <td>0.051054</td>\n","      <td>0.138152</td>\n","      <td>0.297832</td>\n","      <td>0.094548</td>\n","      <td>0.018066</td>\n","      <td>0.018478</td>\n","      <td>0.024748</td>\n","      <td>0.003434</td>\n","      <td>...</td>\n","      <td>0.050333</td>\n","      <td>0.102495</td>\n","      <td>0.069838</td>\n","      <td>0.082066</td>\n","      <td>0.166017</td>\n","      <td>0.273593</td>\n","      <td>0.182716</td>\n","      <td>0.119556</td>\n","      <td>0.125424</td>\n","      <td>Siamese</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.218417</td>\n","      <td>0.184951</td>\n","      <td>0.218417</td>\n","      <td>0.176171</td>\n","      <td>0.218417</td>\n","      <td>0.148506</td>\n","      <td>0.122361</td>\n","      <td>0.079024</td>\n","      <td>0.166223</td>\n","      <td>0.144994</td>\n","      <td>...</td>\n","      <td>0.135554</td>\n","      <td>0.205706</td>\n","      <td>0.132222</td>\n","      <td>0.136953</td>\n","      <td>0.088043</td>\n","      <td>0.178162</td>\n","      <td>0.127782</td>\n","      <td>0.193361</td>\n","      <td>0.196591</td>\n","      <td>saint_bernard</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.224950</td>\n","      <td>0.184881</td>\n","      <td>0.155280</td>\n","      <td>0.212940</td>\n","      <td>0.133371</td>\n","      <td>0.052802</td>\n","      <td>0.054540</td>\n","      <td>0.094103</td>\n","      <td>0.210799</td>\n","      <td>0.161341</td>\n","      <td>...</td>\n","      <td>0.105875</td>\n","      <td>0.148467</td>\n","      <td>0.144005</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.091228</td>\n","      <td>0.066691</td>\n","      <td>0.124647</td>\n","      <td>newfoundland</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 541 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2890ab7-49ac-4f37-9f61-8af958619d60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2890ab7-49ac-4f37-9f61-8af958619d60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2890ab7-49ac-4f37-9f61-8af958619d60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["d = 540\n","df_noncorr = pd.read_csv(path_to_datasets+f\"dataset_noncorr_d={d}.csv\")\n","df_noncorr.head(10)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1670978264485,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"zmcPvcOX_UfW"},"outputs":[],"source":["X_noncorr = df_noncorr[[str(i) for i in range(d)]]\n","y_noncorr = df_noncorr['class']"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1670978264485,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"ByIlWTAO608b","outputId":"bb0d2cf7-2aea-4fdc-a691-fce55a1c1f6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.084298  0.055577  0.052653  0.051070  0.100116  0.111726  0.085606   \n","1  0.240130  0.099940  0.107868  0.240130  0.240130  0.240130  0.085054   \n","2  0.296857  0.296857  0.192027  0.118093  0.144822  0.078502  0.067119   \n","3  0.222998  0.140840  0.159199  0.105568  0.190843  0.129682  0.163091   \n","4  0.278233  0.028802  0.004027  0.006154  0.017805  0.008525  0.007660   \n","5  0.252442  0.067413  0.020861  0.026860  0.137779  0.071512  0.024365   \n","6  0.225421  0.260662  0.122048  0.041961  0.075550  0.013764  0.038639   \n","7  0.042428  0.012829  0.051054  0.138152  0.297832  0.094548  0.018066   \n","8  0.218417  0.184951  0.218417  0.176171  0.218417  0.148506  0.122361   \n","9  0.224950  0.184881  0.155280  0.212940  0.133371  0.052802  0.054540   \n","\n","          7         8         9  ...       530       531       532       533  \\\n","0  0.071323  0.131749  0.280054  ...  0.143287  0.112864  0.186781  0.167077   \n","1  0.138299  0.205619  0.086468  ...  0.088701  0.108184  0.248859  0.108594   \n","2  0.102928  0.073403  0.086981  ...  0.027824  0.021128  0.077877  0.023129   \n","3  0.222998  0.222998  0.093282  ...  0.144664  0.153770  0.185352  0.144374   \n","4  0.049038  0.258007  0.034772  ...  0.192750  0.195922  0.248447  0.231704   \n","5  0.047084  0.380612  0.021658  ...  0.188857  0.172557  0.215076  0.148538   \n","6  0.025091  0.262798  0.262798  ...  0.098766  0.034232  0.026674  0.014406   \n","7  0.018478  0.024748  0.003434  ...  0.040728  0.050333  0.102495  0.069838   \n","8  0.079024  0.166223  0.144994  ...  0.179653  0.135554  0.205706  0.132222   \n","9  0.094103  0.210799  0.161341  ...  0.096869  0.105875  0.148467  0.144005   \n","\n","        534       535       536       537       538       539  \n","0  0.123062  0.206317  0.214587  0.204777  0.210161  0.126280  \n","1  0.101801  0.058171  0.118594  0.088637  0.110307  0.078088  \n","2  0.057161  0.080489  0.364878  0.282017  0.133116  0.154003  \n","3  0.130847  0.150475  0.211966  0.232555  0.185272  0.211561  \n","4  0.096816  0.054017  0.185490  0.059698  0.134580  0.248447  \n","5  0.158630  0.189096  0.215076  0.194341  0.147962  0.211813  \n","6  0.013655  0.055924  0.307993  0.339604  0.122119  0.033844  \n","7  0.082066  0.166017  0.273593  0.182716  0.119556  0.125424  \n","8  0.136953  0.088043  0.178162  0.127782  0.193361  0.196591  \n","9  0.238637  0.238637  0.238637  0.091228  0.066691  0.124647  \n","\n","[10 rows x 540 columns]"],"text/html":["\n","  <div id=\"df-12745ce4-1b03-4c32-9ee8-a07e52754d81\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>530</th>\n","      <th>531</th>\n","      <th>532</th>\n","      <th>533</th>\n","      <th>534</th>\n","      <th>535</th>\n","      <th>536</th>\n","      <th>537</th>\n","      <th>538</th>\n","      <th>539</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.084298</td>\n","      <td>0.055577</td>\n","      <td>0.052653</td>\n","      <td>0.051070</td>\n","      <td>0.100116</td>\n","      <td>0.111726</td>\n","      <td>0.085606</td>\n","      <td>0.071323</td>\n","      <td>0.131749</td>\n","      <td>0.280054</td>\n","      <td>...</td>\n","      <td>0.143287</td>\n","      <td>0.112864</td>\n","      <td>0.186781</td>\n","      <td>0.167077</td>\n","      <td>0.123062</td>\n","      <td>0.206317</td>\n","      <td>0.214587</td>\n","      <td>0.204777</td>\n","      <td>0.210161</td>\n","      <td>0.126280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.240130</td>\n","      <td>0.099940</td>\n","      <td>0.107868</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.240130</td>\n","      <td>0.085054</td>\n","      <td>0.138299</td>\n","      <td>0.205619</td>\n","      <td>0.086468</td>\n","      <td>...</td>\n","      <td>0.088701</td>\n","      <td>0.108184</td>\n","      <td>0.248859</td>\n","      <td>0.108594</td>\n","      <td>0.101801</td>\n","      <td>0.058171</td>\n","      <td>0.118594</td>\n","      <td>0.088637</td>\n","      <td>0.110307</td>\n","      <td>0.078088</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.296857</td>\n","      <td>0.296857</td>\n","      <td>0.192027</td>\n","      <td>0.118093</td>\n","      <td>0.144822</td>\n","      <td>0.078502</td>\n","      <td>0.067119</td>\n","      <td>0.102928</td>\n","      <td>0.073403</td>\n","      <td>0.086981</td>\n","      <td>...</td>\n","      <td>0.027824</td>\n","      <td>0.021128</td>\n","      <td>0.077877</td>\n","      <td>0.023129</td>\n","      <td>0.057161</td>\n","      <td>0.080489</td>\n","      <td>0.364878</td>\n","      <td>0.282017</td>\n","      <td>0.133116</td>\n","      <td>0.154003</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.222998</td>\n","      <td>0.140840</td>\n","      <td>0.159199</td>\n","      <td>0.105568</td>\n","      <td>0.190843</td>\n","      <td>0.129682</td>\n","      <td>0.163091</td>\n","      <td>0.222998</td>\n","      <td>0.222998</td>\n","      <td>0.093282</td>\n","      <td>...</td>\n","      <td>0.144664</td>\n","      <td>0.153770</td>\n","      <td>0.185352</td>\n","      <td>0.144374</td>\n","      <td>0.130847</td>\n","      <td>0.150475</td>\n","      <td>0.211966</td>\n","      <td>0.232555</td>\n","      <td>0.185272</td>\n","      <td>0.211561</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.278233</td>\n","      <td>0.028802</td>\n","      <td>0.004027</td>\n","      <td>0.006154</td>\n","      <td>0.017805</td>\n","      <td>0.008525</td>\n","      <td>0.007660</td>\n","      <td>0.049038</td>\n","      <td>0.258007</td>\n","      <td>0.034772</td>\n","      <td>...</td>\n","      <td>0.192750</td>\n","      <td>0.195922</td>\n","      <td>0.248447</td>\n","      <td>0.231704</td>\n","      <td>0.096816</td>\n","      <td>0.054017</td>\n","      <td>0.185490</td>\n","      <td>0.059698</td>\n","      <td>0.134580</td>\n","      <td>0.248447</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.252442</td>\n","      <td>0.067413</td>\n","      <td>0.020861</td>\n","      <td>0.026860</td>\n","      <td>0.137779</td>\n","      <td>0.071512</td>\n","      <td>0.024365</td>\n","      <td>0.047084</td>\n","      <td>0.380612</td>\n","      <td>0.021658</td>\n","      <td>...</td>\n","      <td>0.188857</td>\n","      <td>0.172557</td>\n","      <td>0.215076</td>\n","      <td>0.148538</td>\n","      <td>0.158630</td>\n","      <td>0.189096</td>\n","      <td>0.215076</td>\n","      <td>0.194341</td>\n","      <td>0.147962</td>\n","      <td>0.211813</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.225421</td>\n","      <td>0.260662</td>\n","      <td>0.122048</td>\n","      <td>0.041961</td>\n","      <td>0.075550</td>\n","      <td>0.013764</td>\n","      <td>0.038639</td>\n","      <td>0.025091</td>\n","      <td>0.262798</td>\n","      <td>0.262798</td>\n","      <td>...</td>\n","      <td>0.098766</td>\n","      <td>0.034232</td>\n","      <td>0.026674</td>\n","      <td>0.014406</td>\n","      <td>0.013655</td>\n","      <td>0.055924</td>\n","      <td>0.307993</td>\n","      <td>0.339604</td>\n","      <td>0.122119</td>\n","      <td>0.033844</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.042428</td>\n","      <td>0.012829</td>\n","      <td>0.051054</td>\n","      <td>0.138152</td>\n","      <td>0.297832</td>\n","      <td>0.094548</td>\n","      <td>0.018066</td>\n","      <td>0.018478</td>\n","      <td>0.024748</td>\n","      <td>0.003434</td>\n","      <td>...</td>\n","      <td>0.040728</td>\n","      <td>0.050333</td>\n","      <td>0.102495</td>\n","      <td>0.069838</td>\n","      <td>0.082066</td>\n","      <td>0.166017</td>\n","      <td>0.273593</td>\n","      <td>0.182716</td>\n","      <td>0.119556</td>\n","      <td>0.125424</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.218417</td>\n","      <td>0.184951</td>\n","      <td>0.218417</td>\n","      <td>0.176171</td>\n","      <td>0.218417</td>\n","      <td>0.148506</td>\n","      <td>0.122361</td>\n","      <td>0.079024</td>\n","      <td>0.166223</td>\n","      <td>0.144994</td>\n","      <td>...</td>\n","      <td>0.179653</td>\n","      <td>0.135554</td>\n","      <td>0.205706</td>\n","      <td>0.132222</td>\n","      <td>0.136953</td>\n","      <td>0.088043</td>\n","      <td>0.178162</td>\n","      <td>0.127782</td>\n","      <td>0.193361</td>\n","      <td>0.196591</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.224950</td>\n","      <td>0.184881</td>\n","      <td>0.155280</td>\n","      <td>0.212940</td>\n","      <td>0.133371</td>\n","      <td>0.052802</td>\n","      <td>0.054540</td>\n","      <td>0.094103</td>\n","      <td>0.210799</td>\n","      <td>0.161341</td>\n","      <td>...</td>\n","      <td>0.096869</td>\n","      <td>0.105875</td>\n","      <td>0.148467</td>\n","      <td>0.144005</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.238637</td>\n","      <td>0.091228</td>\n","      <td>0.066691</td>\n","      <td>0.124647</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 540 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12745ce4-1b03-4c32-9ee8-a07e52754d81')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-12745ce4-1b03-4c32-9ee8-a07e52754d81 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-12745ce4-1b03-4c32-9ee8-a07e52754d81');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}],"source":["X_noncorr.head(10)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1670978264486,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"9rRPYWnt61dm","outputId":"43c67110-87cf-40d7-9f86-e0607d54cd34"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    german_shorthaired\n","1            Maine_Coon\n","2               Siamese\n","3          newfoundland\n","4         saint_bernard\n","5          newfoundland\n","6            Maine_Coon\n","7               Siamese\n","8         saint_bernard\n","9          newfoundland\n","Name: class, dtype: object"]},"metadata":{},"execution_count":22}],"source":["y_noncorr.head(10)"]},{"cell_type":"markdown","metadata":{"id":"7aTsWHPW3dP-"},"source":["## Summary"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1670978264486,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"ks2xs3W63brK"},"outputs":[],"source":["X_all = [X_normal,X_900,X_pca,X_noncorr]\n","y_all = [y_normal,y_900,y_pca,y_noncorr]\n","names_datasets = ['normal_d=1764','normal_d=900','pca_d=459','noncorr_d=540']"]},{"cell_type":"markdown","metadata":{"id":"CEDuL7lyDdDw"},"source":["## Binary classes"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1670978264487,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"44iZ1zXh_W_4"},"outputs":[],"source":["classes_2 = {'german_shorthaired':'dog','newfoundland':'dog','saint_bernard':'dog', 'Maine_Coon':'cat', 'Siamese':'cat'}\n","y_normal_2 = [classes_2[breed] for breed in y_normal]\n","y_900_2 = [classes_2[breed] for breed in y_900]\n","y_pca_2 = [classes_2[breed] for breed in y_pca]\n","y_noncorr_2 = [classes_2[breed] for breed in y_noncorr]"]},{"cell_type":"markdown","metadata":{"id":"kaP_79abm3V3"},"source":["# Functions"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1670978264491,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"afYG9HpwfH_H"},"outputs":[],"source":["class CrossValidation(Enum):\n","    HOLDOUT = 0\n","    KFOLD = 1\n","\n","class Classifier(Enum):\n","    DUMMY = 0\n","    KNN = 1\n","    DT = 2\n","    GNB = 3\n","    MLP = 4\n","    BAGGING = 5\n","    BOOSTING = 6\n","    RANDOM_FOREST = 7\n","    STACKING = 8\n"," \n","def clf_object(classifier):\n","    if classifier == Classifier.DUMMY:\n","        return DummyClassifier()\n","    elif classifier == Classifier.KNN:\n","        return KNeighborsClassifier()\n","    elif classifier == Classifier.DT:\n","        return DecisionTreeClassifier()\n","    elif classifier == Classifier.GNB:\n","        return GaussianNB()\n","    elif classifier == Classifier.MLP:\n","        return MLPClassifier()\n","    if classifier == Classifier.BAGGING:\n","        return BaggingClassifier()\n","    elif classifier == Classifier.BOOSTING:\n","        return AdaBoostClassifier()\n","    elif classifier == Classifier.RANDOM_FOREST:\n","        return RandomForestClassifier()\n","    elif classifier == Classifier.STACKING:\n","        return StackingClassifier([('nb',GaussianNB())],\n","                                  final_estimator=\\\n","                                  LogisticRegression(max_iter=500))\n","    else:\n","        raise NameError(f\"There is no classifier called '{classifier.name}' \\\n","implemented\")\n","\n","def compute_hyperparams_permutations(hyperparams):\n","    \n","    hyperparams_values = list(hyperparams.values())\n","    hyperparams_permutations =\\\n","    [{param_name:value \n","        for param_name,value in zip(hyperparams.keys(),elem)}\n","        for elem in list(itertools.product(*hyperparams_values))]\n","    \n","    return hyperparams_permutations\n","\n","def height_hidden_layer(input_layer_size,output_layer_size,size_types:str):\n","    dic_map = {'O':output_layer_size,'T':input_layer_size}\n","    dic_map['A'] = (dic_map['O']+dic_map['T'])//2\n","    dic_map['OA'] = (dic_map['O']+dic_map['A'])//2\n","    dic_map['AT'] = (dic_map['A']+dic_map['T'])//2\n","    heights = dic_map[size_types]\n","    return heights\n","\n","def clf_accuracies(X,y,classifier,cross_validation_method=CrossValidation.HOLDOUT,\n","                   test_size=0.1,\n","                   hyperparams=dict(),\n","                   verbose=True):\n","    \n","    hyperparams = deepcopy(hyperparams)\n","    \n","    hyperparams_permutations = [{}]\n","    if len(hyperparams.keys())!=0:\n","        hyperparams_permutations = compute_hyperparams_permutations(hyperparams)    \n","    \n","    if cross_validation_method==CrossValidation.HOLDOUT:\n","        X_train, X_test, y_train, y_test =\\\n","        train_test_split(X, y,test_size = test_size, random_state = 0)\n","        n_train = int((1-test_size)*100)\n","        n_test = int(test_size*100)\n","        title = f'{n_train}/{n_test}-{cross_validation_method.name}'\n","    elif cross_validation_method==CrossValidation.KFOLD:\n","        n_fold = int(test_size*100)\n","        kf = KFold(n_splits=n_fold, random_state=0, shuffle=True)\n","        title = f'{n_fold}-{cross_validation_method.name[1:]}'\n","    \n","    if verbose:\n","        print()\n","        print(f'{title}:')\n","    \n","    dict_accuracies_op = dict()\n","    for hyperparams_group in hyperparams_permutations:\n","        \n","        #change hidden_layer_sizes parameter to an integer number\n","        if 'hidden_layer_sizes' in hyperparams_group.keys() or\\\n","           'base_estimator__hidden_layer_sizes' in hyperparams_group.keys():\n","            if 'hidden_layer_sizes' in hyperparams_group.keys():\n","                hyperparam_name = 'hidden_layer_sizes'\n","            else:\n","                hyperparam_name = 'base_estimator__hidden_layer_sizes'\n","            hidden_layer_sizes_changed = False\n","            if isinstance(hyperparams_group[hyperparam_name],str):\n","                hidden_layer_size_str = hyperparams_group[hyperparam_name]\n","                output_layer_size = len(y.unique())\n","                input_layer_size = X.shape[1]\n","                hyperparams_group[hyperparam_name] =\\\n","                height_hidden_layer(input_layer_size,output_layer_size,\n","                                    hidden_layer_size_str)\n","                hidden_layer_sizes_changed = True\n","        \n","        clf = clf_object(classifier)\n","        clf.set_params(**hyperparams_group)\n","        \n","        #change back hidden_layer_sizes parameter to a string\n","        if 'hidden_layer_sizes' in hyperparams_group.keys() or\\\n","           'base_estimator__hidden_layer_sizes' in hyperparams_group.keys():\n","            if hidden_layer_sizes_changed:\n","                hyperparams_group[hyperparam_name] = hidden_layer_size_str\n","\n","        if cross_validation_method==CrossValidation.HOLDOUT:\n","            clf.fit(X_train,y_train)\n","            y_pred = clf.predict(X_test)  \n","            accuracy_test = metrics.accuracy_score(y_test, y_pred)\n","        elif cross_validation_method==CrossValidation.KFOLD:\n","            scores = cross_val_score(clf, X, y, scoring='accuracy', cv=kf)\n","            accuracy_test = np.mean(scores)\n","\n","        op_clf = str(hyperparams_group).replace(' ','')\\\n","        .replace('\\'','').replace('{','').replace('}','').replace(':','=')\n","        op_clf = re.sub('hidden_layer_sizes=[\\d]+,', '', op_clf)\n","        op = (classifier.name,op_clf)\n","        dict_accuracies_op[op] = accuracy_test\n","        \n","        if verbose:\n","            print(f'\\tAccuracy{op}: {accuracy_test:.3f}')\n","        \n","    dict_accuracies={f'{title}': dict_accuracies_op}\n","        \n","    return dict_accuracies\n","\n","def scaler_object(name_classifier):\n","    if name_classifier.lower() == 'standard':\n","        return StandardScaler()\n","    elif name_classifier.lower() == 'minmax':\n","        return MinMaxScaler()\n","    else:\n","        raise NameError(f\"There is no classifier called '{name_classifier}' \\\n","implemented\")\n","\n","def df_accuracies(X_all,y_all,names_datasets,scalers,classifier,hyperparams=dict(),\n","                  verbose = False):\n","\n","    dfs = dict()\n","    for X,y,name,scaler_name in zip(X_all,y_all,names_datasets,scalers):\n","        if scaler_name!= None:\n","            scaler = scaler_object(scaler_name)\n","            X = scaler.fit_transform(X)\n","        \n","        accuracies_Xy = dict()\n","        \n","        #Holdout 70/30, 80/20 and 90/10\n","        rate_test_sizes = [0.3, 0.2, 0.1]\n","        for current_test_size in rate_test_sizes:\n","            accuracies_Xy.update(\n","                clf_accuracies(X,y,classifier,\n","                               cross_validation_method=CrossValidation.HOLDOUT,\n","                               test_size=current_test_size,hyperparams=hyperparams,\n","                               verbose = verbose))\n","        #10-fold\n","        accuracies_Xy.update(\n","            clf_accuracies(X,y,classifier,\n","                           cross_validation_method=CrossValidation.KFOLD,\n","                           test_size=0.1,hyperparams=hyperparams,verbose = verbose))\n","        \n","        df = pd.DataFrame(accuracies_Xy).T\n","        df.reset_index(inplace=True)\n","        df.rename(columns = {'index':'train/test_type'}, inplace = True)\n","        df['dataset'] = [name]*len(df)\n","        df.set_index(['dataset','train/test_type'],inplace = True)\n","        dfs[name] = df\n","    return pd.concat(list(dfs.values()), axis=0)"]},{"cell_type":"markdown","source":["# KNN"],"metadata":{"id":"LOuegBRHfnXM"}},{"cell_type":"code","source":["classifier = Classifier.KNN\n","params = {'n_neighbors':[1,2,3,4,5]}\n","df_acc_knn = df_accuracies(X_all,y_all,names_datasets,[None]*len(X_all),classifier,\n","              hyperparams=params,verbose=False)\n","df_acc_knn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"oLrmUnIIgLNw","executionInfo":{"status":"ok","timestamp":1670870663135,"user_tz":180,"elapsed":15247,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"495a32f4-ce26-4dbc-fec4-c6c0edf7af69"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        KNN                              \\\n","                              n_neighbors=1 n_neighbors=2 n_neighbors=3   \n","dataset       train/test_type                                             \n","normal_d=1764 70/30-HOLDOUT        0.346667      0.290000      0.313333   \n","              80/20-HOLDOUT        0.340000      0.325000      0.315000   \n","              90/10-HOLDOUT        0.320000      0.340000      0.360000   \n","              10-FOLD              0.343000      0.333000      0.340000   \n","normal_d=900  70/30-HOLDOUT        0.393333      0.370000      0.386667   \n","              80/20-HOLDOUT        0.430000      0.380000      0.405000   \n","              90/10-HOLDOUT        0.480000      0.380000      0.410000   \n","              10-FOLD              0.401000      0.395000      0.372000   \n","pca_d=459     70/30-HOLDOUT        0.330000      0.276667      0.300000   \n","              80/20-HOLDOUT        0.325000      0.285000      0.305000   \n","              90/10-HOLDOUT        0.320000      0.300000      0.330000   \n","              10-FOLD              0.350000      0.331000      0.330000   \n","noncorr_d=540 70/30-HOLDOUT        0.293333      0.286667      0.296667   \n","              80/20-HOLDOUT        0.330000      0.300000      0.295000   \n","              90/10-HOLDOUT        0.310000      0.340000      0.320000   \n","              10-FOLD              0.336000      0.319000      0.312000   \n","\n","                                                           \n","                              n_neighbors=4 n_neighbors=5  \n","dataset       train/test_type                              \n","normal_d=1764 70/30-HOLDOUT        0.263333      0.280000  \n","              80/20-HOLDOUT        0.270000      0.275000  \n","              90/10-HOLDOUT        0.340000      0.330000  \n","              10-FOLD              0.324000      0.326000  \n","normal_d=900  70/30-HOLDOUT        0.363333      0.353333  \n","              80/20-HOLDOUT        0.380000      0.375000  \n","              90/10-HOLDOUT        0.500000      0.440000  \n","              10-FOLD              0.366000      0.354000  \n","pca_d=459     70/30-HOLDOUT        0.303333      0.296667  \n","              80/20-HOLDOUT        0.305000      0.275000  \n","              90/10-HOLDOUT        0.350000      0.310000  \n","              10-FOLD              0.339000      0.328000  \n","noncorr_d=540 70/30-HOLDOUT        0.293333      0.293333  \n","              80/20-HOLDOUT        0.275000      0.280000  \n","              90/10-HOLDOUT        0.310000      0.380000  \n","              10-FOLD              0.306000      0.329000  "],"text/html":["\n","  <div id=\"df-583cd202-8734-4ae5-b53e-da4e3616a6d9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"5\" halign=\"left\">KNN</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>n_neighbors=1</th>\n","      <th>n_neighbors=2</th>\n","      <th>n_neighbors=3</th>\n","      <th>n_neighbors=4</th>\n","      <th>n_neighbors=5</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.346667</td>\n","      <td>0.290000</td>\n","      <td>0.313333</td>\n","      <td>0.263333</td>\n","      <td>0.280000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.340000</td>\n","      <td>0.325000</td>\n","      <td>0.315000</td>\n","      <td>0.270000</td>\n","      <td>0.275000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.320000</td>\n","      <td>0.340000</td>\n","      <td>0.360000</td>\n","      <td>0.340000</td>\n","      <td>0.330000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.343000</td>\n","      <td>0.333000</td>\n","      <td>0.340000</td>\n","      <td>0.324000</td>\n","      <td>0.326000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.393333</td>\n","      <td>0.370000</td>\n","      <td>0.386667</td>\n","      <td>0.363333</td>\n","      <td>0.353333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.430000</td>\n","      <td>0.380000</td>\n","      <td>0.405000</td>\n","      <td>0.380000</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.480000</td>\n","      <td>0.380000</td>\n","      <td>0.410000</td>\n","      <td>0.500000</td>\n","      <td>0.440000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.401000</td>\n","      <td>0.395000</td>\n","      <td>0.372000</td>\n","      <td>0.366000</td>\n","      <td>0.354000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.330000</td>\n","      <td>0.276667</td>\n","      <td>0.300000</td>\n","      <td>0.303333</td>\n","      <td>0.296667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.325000</td>\n","      <td>0.285000</td>\n","      <td>0.305000</td>\n","      <td>0.305000</td>\n","      <td>0.275000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.320000</td>\n","      <td>0.300000</td>\n","      <td>0.330000</td>\n","      <td>0.350000</td>\n","      <td>0.310000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.350000</td>\n","      <td>0.331000</td>\n","      <td>0.330000</td>\n","      <td>0.339000</td>\n","      <td>0.328000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.293333</td>\n","      <td>0.286667</td>\n","      <td>0.296667</td>\n","      <td>0.293333</td>\n","      <td>0.293333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.330000</td>\n","      <td>0.300000</td>\n","      <td>0.295000</td>\n","      <td>0.275000</td>\n","      <td>0.280000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.310000</td>\n","      <td>0.340000</td>\n","      <td>0.320000</td>\n","      <td>0.310000</td>\n","      <td>0.380000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.336000</td>\n","      <td>0.319000</td>\n","      <td>0.312000</td>\n","      <td>0.306000</td>\n","      <td>0.329000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-583cd202-8734-4ae5-b53e-da4e3616a6d9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-583cd202-8734-4ae5-b53e-da4e3616a6d9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-583cd202-8734-4ae5-b53e-da4e3616a6d9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":155}]},{"cell_type":"code","source":["df_acc_knn.to_csv(path_to_accuracies+f'{classifier.name}_accuracies.csv',index=True)"],"metadata":{"id":"R1G4IGoaol-d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Decision Tree"],"metadata":{"id":"OTABK9YtfpF5"}},{"cell_type":"code","source":["classifier = Classifier.DT\n","params = {'max_depth':[3,4,5,6,7]}\n","df_acc_dt = df_accuracies(X_all,y_all,names_datasets,[None]*len(X_all),classifier,\n","              hyperparams=params,verbose=False)\n","df_acc_dt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"luiMIJLcpzse","executionInfo":{"status":"ok","timestamp":1670871156732,"user_tz":180,"elapsed":123311,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"6241d37a-e81c-4bd3-9d65-7a90b9f16da0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       DT                                      \\\n","                              max_depth=3 max_depth=4 max_depth=5 max_depth=6   \n","dataset       train/test_type                                                   \n","normal_d=1764 70/30-HOLDOUT      0.316667    0.316667    0.313333    0.323333   \n","              80/20-HOLDOUT      0.300000    0.305000    0.290000    0.355000   \n","              90/10-HOLDOUT      0.350000    0.320000    0.310000    0.330000   \n","              10-FOLD            0.309000    0.319000    0.310000    0.311000   \n","normal_d=900  70/30-HOLDOUT      0.296667    0.350000    0.346667    0.333333   \n","              80/20-HOLDOUT      0.335000    0.360000    0.335000    0.340000   \n","              90/10-HOLDOUT      0.310000    0.340000    0.400000    0.440000   \n","              10-FOLD            0.311000    0.347000    0.377000    0.384000   \n","pca_d=459     70/30-HOLDOUT      0.360000    0.363333    0.326667    0.356667   \n","              80/20-HOLDOUT      0.325000    0.335000    0.375000    0.315000   \n","              90/10-HOLDOUT      0.340000    0.330000    0.360000    0.350000   \n","              10-FOLD            0.360000    0.353000    0.351000    0.321000   \n","noncorr_d=540 70/30-HOLDOUT      0.330000    0.313333    0.280000    0.303333   \n","              80/20-HOLDOUT      0.300000    0.305000    0.330000    0.305000   \n","              90/10-HOLDOUT      0.360000    0.300000    0.320000    0.340000   \n","              10-FOLD            0.300000    0.312000    0.287000    0.301000   \n","\n","                                           \n","                              max_depth=7  \n","dataset       train/test_type              \n","normal_d=1764 70/30-HOLDOUT      0.280000  \n","              80/20-HOLDOUT      0.370000  \n","              90/10-HOLDOUT      0.350000  \n","              10-FOLD            0.334000  \n","normal_d=900  70/30-HOLDOUT      0.310000  \n","              80/20-HOLDOUT      0.365000  \n","              90/10-HOLDOUT      0.470000  \n","              10-FOLD            0.366000  \n","pca_d=459     70/30-HOLDOUT      0.313333  \n","              80/20-HOLDOUT      0.315000  \n","              90/10-HOLDOUT      0.330000  \n","              10-FOLD            0.312000  \n","noncorr_d=540 70/30-HOLDOUT      0.286667  \n","              80/20-HOLDOUT      0.285000  \n","              90/10-HOLDOUT      0.330000  \n","              10-FOLD            0.317000  "],"text/html":["\n","  <div id=\"df-e24212fc-8580-4539-ad96-c0fbeda893bb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"5\" halign=\"left\">DT</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>max_depth=3</th>\n","      <th>max_depth=4</th>\n","      <th>max_depth=5</th>\n","      <th>max_depth=6</th>\n","      <th>max_depth=7</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.316667</td>\n","      <td>0.316667</td>\n","      <td>0.313333</td>\n","      <td>0.323333</td>\n","      <td>0.280000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.300000</td>\n","      <td>0.305000</td>\n","      <td>0.290000</td>\n","      <td>0.355000</td>\n","      <td>0.370000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.350000</td>\n","      <td>0.320000</td>\n","      <td>0.310000</td>\n","      <td>0.330000</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.309000</td>\n","      <td>0.319000</td>\n","      <td>0.310000</td>\n","      <td>0.311000</td>\n","      <td>0.334000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.296667</td>\n","      <td>0.350000</td>\n","      <td>0.346667</td>\n","      <td>0.333333</td>\n","      <td>0.310000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.335000</td>\n","      <td>0.360000</td>\n","      <td>0.335000</td>\n","      <td>0.340000</td>\n","      <td>0.365000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.310000</td>\n","      <td>0.340000</td>\n","      <td>0.400000</td>\n","      <td>0.440000</td>\n","      <td>0.470000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.311000</td>\n","      <td>0.347000</td>\n","      <td>0.377000</td>\n","      <td>0.384000</td>\n","      <td>0.366000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.360000</td>\n","      <td>0.363333</td>\n","      <td>0.326667</td>\n","      <td>0.356667</td>\n","      <td>0.313333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.325000</td>\n","      <td>0.335000</td>\n","      <td>0.375000</td>\n","      <td>0.315000</td>\n","      <td>0.315000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.340000</td>\n","      <td>0.330000</td>\n","      <td>0.360000</td>\n","      <td>0.350000</td>\n","      <td>0.330000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.360000</td>\n","      <td>0.353000</td>\n","      <td>0.351000</td>\n","      <td>0.321000</td>\n","      <td>0.312000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.330000</td>\n","      <td>0.313333</td>\n","      <td>0.280000</td>\n","      <td>0.303333</td>\n","      <td>0.286667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.300000</td>\n","      <td>0.305000</td>\n","      <td>0.330000</td>\n","      <td>0.305000</td>\n","      <td>0.285000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.360000</td>\n","      <td>0.300000</td>\n","      <td>0.320000</td>\n","      <td>0.340000</td>\n","      <td>0.330000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.300000</td>\n","      <td>0.312000</td>\n","      <td>0.287000</td>\n","      <td>0.301000</td>\n","      <td>0.317000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e24212fc-8580-4539-ad96-c0fbeda893bb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e24212fc-8580-4539-ad96-c0fbeda893bb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e24212fc-8580-4539-ad96-c0fbeda893bb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":163}]},{"cell_type":"code","source":["df_acc_dt.to_csv(path_to_accuracies+f'{classifier.name}_accuracies.csv',index=True)"],"metadata":{"id":"NCF7I9FHrGa0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gaussian Naive Bayes"],"metadata":{"id":"9dH-Ifejfo_w"}},{"cell_type":"code","source":["classifier = Classifier.GNB\n","df_acc_gnb = df_accuracies(X_all,y_all,names_datasets,[None]*len(X_all),classifier,\n","              hyperparams=dict(),verbose=False)\n","df_acc_gnb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"NKrQffnIfyFd","executionInfo":{"status":"ok","timestamp":1670871372197,"user_tz":180,"elapsed":3220,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"7a16245d-d582-4e25-dfa1-0ee6ac01b21e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                    GNB\n","                                       \n","dataset       train/test_type          \n","normal_d=1764 70/30-HOLDOUT    0.500000\n","              80/20-HOLDOUT    0.505000\n","              90/10-HOLDOUT    0.490000\n","              10-FOLD          0.507000\n","normal_d=900  70/30-HOLDOUT    0.556667\n","              80/20-HOLDOUT    0.585000\n","              90/10-HOLDOUT    0.630000\n","              10-FOLD          0.537000\n","pca_d=459     70/30-HOLDOUT    0.426667\n","              80/20-HOLDOUT    0.445000\n","              90/10-HOLDOUT    0.490000\n","              10-FOLD          0.415000\n","noncorr_d=540 70/30-HOLDOUT    0.500000\n","              80/20-HOLDOUT    0.500000\n","              90/10-HOLDOUT    0.470000\n","              10-FOLD          0.505000"],"text/html":["\n","  <div id=\"df-a9fc34c3-226d-4c0f-bb97-a02e8431148b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>GNB</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.505000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.490000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.507000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.556667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.585000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.630000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.537000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.426667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.445000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.490000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.415000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.470000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.505000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9fc34c3-226d-4c0f-bb97-a02e8431148b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a9fc34c3-226d-4c0f-bb97-a02e8431148b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a9fc34c3-226d-4c0f-bb97-a02e8431148b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["df_acc_gnb.to_csv(path_to_accuracies+f'{classifier.name}_accuracies.csv',index=True)"],"metadata":{"id":"c-G1QZ3BsaXX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MLP"],"metadata":{"id":"AGKAjMGlfyj0"}},{"cell_type":"code","source":["classifier = Classifier.MLP\n","scalers = ['standard','standard',None,'standard']"],"metadata":{"id":"gK7jCl0axzlu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Activation functions"],"metadata":{"id":"Zckpze_bv1uf"}},{"cell_type":"code","source":["params = {'activation':['identity','logistic','tanh','relu']}\n","df_acc_mlp_act = df_accuracies(X_all,y_all,names_datasets,scalers,classifier,\n","              hyperparams=params,verbose=True)\n","df_acc_mlp_act"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zv54EnbovxTP","executionInfo":{"status":"ok","timestamp":1670874689188,"user_tz":180,"elapsed":1263917,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"cd333051-4f91-4d95-f81a-9b4f837dcefb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=identity')): 0.493\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.513\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.500\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.533\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.485\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.495\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.495\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.540\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.510\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.540\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.560\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.590\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.505\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.539\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.542\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.563\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.500\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.523\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.507\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.530\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.505\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.550\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.545\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.605\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.500\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.540\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.640\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.640\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.495\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.526\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.534\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.569\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.430\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.457\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.453\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.463\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.420\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.460\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.445\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.465\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.480\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.470\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.530\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.470\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.471\n","\n","\tAccuracy(('MLP', 'activation=logistic')): 0.490\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.507\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.489\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.457\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.467\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.480\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.513\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.450\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.485\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.510\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.465\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.450\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.470\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.510\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.510\n","\n","\tAccuracy(('MLP', 'activation=identity')): 0.473\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\tAccuracy(('MLP', 'activation=logistic')): 0.493\n","\n","\tAccuracy(('MLP', 'activation=tanh')): 0.508\n","\n","\tAccuracy(('MLP', 'activation=relu')): 0.529\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              MLP                      \\\n","                              activation=identity activation=logistic   \n","dataset       train/test_type                                           \n","normal_d=1764 70/30-HOLDOUT              0.493333            0.513333   \n","              80/20-HOLDOUT              0.485000            0.495000   \n","              90/10-HOLDOUT              0.510000            0.540000   \n","              10-FOLD                    0.505000            0.539000   \n","normal_d=900  70/30-HOLDOUT              0.500000            0.523333   \n","              80/20-HOLDOUT              0.505000            0.550000   \n","              90/10-HOLDOUT              0.500000            0.540000   \n","              10-FOLD                    0.495000            0.526000   \n","pca_d=459     70/30-HOLDOUT              0.430000            0.456667   \n","              80/20-HOLDOUT              0.420000            0.460000   \n","              90/10-HOLDOUT              0.480000            0.470000   \n","              10-FOLD                    0.471000            0.490000   \n","noncorr_d=540 70/30-HOLDOUT              0.456667            0.466667   \n","              80/20-HOLDOUT              0.450000            0.485000   \n","              90/10-HOLDOUT              0.450000            0.470000   \n","              10-FOLD                    0.473000            0.493000   \n","\n","                                                               \n","                              activation=tanh activation=relu  \n","dataset       train/test_type                                  \n","normal_d=1764 70/30-HOLDOUT          0.500000        0.533333  \n","              80/20-HOLDOUT          0.495000        0.540000  \n","              90/10-HOLDOUT          0.560000        0.590000  \n","              10-FOLD                0.542000        0.563000  \n","normal_d=900  70/30-HOLDOUT          0.506667        0.530000  \n","              80/20-HOLDOUT          0.545000        0.605000  \n","              90/10-HOLDOUT          0.640000        0.640000  \n","              10-FOLD                0.534000        0.569000  \n","pca_d=459     70/30-HOLDOUT          0.453333        0.463333  \n","              80/20-HOLDOUT          0.445000        0.465000  \n","              90/10-HOLDOUT          0.530000        0.470000  \n","              10-FOLD                0.507000        0.489000  \n","noncorr_d=540 70/30-HOLDOUT          0.480000        0.513333  \n","              80/20-HOLDOUT          0.510000        0.465000  \n","              90/10-HOLDOUT          0.510000        0.510000  \n","              10-FOLD                0.508000        0.529000  "],"text/html":["\n","  <div id=\"df-2c652061-9e86-43dc-8f04-a99fc2ffc8ef\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"4\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>activation=identity</th>\n","      <th>activation=logistic</th>\n","      <th>activation=tanh</th>\n","      <th>activation=relu</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.493333</td>\n","      <td>0.513333</td>\n","      <td>0.500000</td>\n","      <td>0.533333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.485000</td>\n","      <td>0.495000</td>\n","      <td>0.495000</td>\n","      <td>0.540000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.510000</td>\n","      <td>0.540000</td>\n","      <td>0.560000</td>\n","      <td>0.590000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.505000</td>\n","      <td>0.539000</td>\n","      <td>0.542000</td>\n","      <td>0.563000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.500000</td>\n","      <td>0.523333</td>\n","      <td>0.506667</td>\n","      <td>0.530000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.505000</td>\n","      <td>0.550000</td>\n","      <td>0.545000</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.500000</td>\n","      <td>0.540000</td>\n","      <td>0.640000</td>\n","      <td>0.640000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.495000</td>\n","      <td>0.526000</td>\n","      <td>0.534000</td>\n","      <td>0.569000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.430000</td>\n","      <td>0.456667</td>\n","      <td>0.453333</td>\n","      <td>0.463333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.420000</td>\n","      <td>0.460000</td>\n","      <td>0.445000</td>\n","      <td>0.465000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.480000</td>\n","      <td>0.470000</td>\n","      <td>0.530000</td>\n","      <td>0.470000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.471000</td>\n","      <td>0.490000</td>\n","      <td>0.507000</td>\n","      <td>0.489000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.456667</td>\n","      <td>0.466667</td>\n","      <td>0.480000</td>\n","      <td>0.513333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.450000</td>\n","      <td>0.485000</td>\n","      <td>0.510000</td>\n","      <td>0.465000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.450000</td>\n","      <td>0.470000</td>\n","      <td>0.510000</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.473000</td>\n","      <td>0.493000</td>\n","      <td>0.508000</td>\n","      <td>0.529000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c652061-9e86-43dc-8f04-a99fc2ffc8ef')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2c652061-9e86-43dc-8f04-a99fc2ffc8ef button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2c652061-9e86-43dc-8f04-a99fc2ffc8ef');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":173}]},{"cell_type":"code","source":["df_acc_mlp_act.to_csv(path_to_accuracies+f'{classifier.name}_actv_accuracies.csv',index=True)"],"metadata":{"id":"k2-PLDLyxe1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_acc_mlp_act.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"O-UI_Auvv7Zu","executionInfo":{"status":"ok","timestamp":1670874689191,"user_tz":180,"elapsed":39,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"6cc2f542-3d15-4084-9799-138dbf0fae9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      MLP                                                    \n","      activation=identity activation=logistic activation=tanh activation=relu\n","count           16.000000           16.000000       16.000000       16.000000\n","mean             0.476500            0.501125        0.516625        0.529688\n","std              0.027996            0.032028        0.045172        0.053478\n","min              0.420000            0.456667        0.445000        0.463333\n","25%              0.455000            0.470000        0.498750        0.484250\n","50%              0.482500            0.494000        0.509000        0.529500\n","75%              0.500000            0.529250        0.536000        0.564500\n","max              0.510000            0.550000        0.640000        0.640000"],"text/html":["\n","  <div id=\"df-8692b716-3041-43e0-90c6-67fd1fc3107b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"4\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>activation=identity</th>\n","      <th>activation=logistic</th>\n","      <th>activation=tanh</th>\n","      <th>activation=relu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.476500</td>\n","      <td>0.501125</td>\n","      <td>0.516625</td>\n","      <td>0.529688</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.027996</td>\n","      <td>0.032028</td>\n","      <td>0.045172</td>\n","      <td>0.053478</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.420000</td>\n","      <td>0.456667</td>\n","      <td>0.445000</td>\n","      <td>0.463333</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.455000</td>\n","      <td>0.470000</td>\n","      <td>0.498750</td>\n","      <td>0.484250</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.482500</td>\n","      <td>0.494000</td>\n","      <td>0.509000</td>\n","      <td>0.529500</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.500000</td>\n","      <td>0.529250</td>\n","      <td>0.536000</td>\n","      <td>0.564500</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.510000</td>\n","      <td>0.550000</td>\n","      <td>0.640000</td>\n","      <td>0.640000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8692b716-3041-43e0-90c6-67fd1fc3107b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8692b716-3041-43e0-90c6-67fd1fc3107b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8692b716-3041-43e0-90c6-67fd1fc3107b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":175}]},{"cell_type":"markdown","source":["## Hidden layer sizes"],"metadata":{"id":"YNqNVdVtwX1W"}},{"cell_type":"code","source":["params = {'activation':['relu'],'hidden_layer_sizes':['O','OA','A','AT', 'T']}\n","df_acc_mlp_hls = df_accuracies(X_all,y_all,names_datasets,scalers,classifier,\n","              hyperparams=params,verbose=True)\n","df_acc_mlp_hls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nelloDcVwdV_","executionInfo":{"status":"ok","timestamp":1670956223614,"user_tz":180,"elapsed":1940366,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"aff025bf-9246-4f43-c271-fe7e116655b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","70/30-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.437\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.533\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.517\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.533\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.513\n","\n","80/20-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.435\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.545\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.525\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.525\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.525\n","\n","90/10-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.550\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.530\n","\n","10-FOLD:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.463\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.570\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.559\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.560\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.563\n","\n","70/30-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.463\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.590\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.557\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.527\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.547\n","\n","80/20-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.570\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.625\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.600\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.605\n","\n","90/10-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.570\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.580\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.600\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.620\n","\n","10-FOLD:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.480\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.574\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.569\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.574\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.581\n","\n","70/30-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.323\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.453\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.463\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.450\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.453\n","\n","80/20-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.365\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.420\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.420\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.480\n","\n","90/10-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.440\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.500\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.510\n","\n","10-FOLD:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.454\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.488\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.497\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.502\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.526\n","\n","70/30-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.460\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.507\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.510\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.510\n","\n","80/20-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.410\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.505\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.500\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.520\n","\n","90/10-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.500\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.510\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.480\n","\n","10-FOLD:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=O'): 0.454\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA'): 0.519\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=A'): 0.531\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=AT'): 0.551\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=T'): 0.530\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                               MLP  \\\n","                              activation=relu,hidden_layer_sizes=O   \n","dataset       train/test_type                                        \n","normal_d=1764 70/30-HOLDOUT                               0.436667   \n","              80/20-HOLDOUT                               0.435000   \n","              90/10-HOLDOUT                               0.540000   \n","              10-FOLD                                     0.463000   \n","normal_d=900  70/30-HOLDOUT                               0.463333   \n","              80/20-HOLDOUT                               0.520000   \n","              90/10-HOLDOUT                               0.540000   \n","              10-FOLD                                     0.480000   \n","pca_d=459     70/30-HOLDOUT                               0.323333   \n","              80/20-HOLDOUT                               0.365000   \n","              90/10-HOLDOUT                               0.440000   \n","              10-FOLD                                     0.454000   \n","noncorr_d=540 70/30-HOLDOUT                               0.460000   \n","              80/20-HOLDOUT                               0.410000   \n","              90/10-HOLDOUT                               0.490000   \n","              10-FOLD                                     0.454000   \n","\n","                                                                     \\\n","                              activation=relu,hidden_layer_sizes=OA   \n","dataset       train/test_type                                         \n","normal_d=1764 70/30-HOLDOUT                                0.533333   \n","              80/20-HOLDOUT                                0.545000   \n","              90/10-HOLDOUT                                0.550000   \n","              10-FOLD                                      0.570000   \n","normal_d=900  70/30-HOLDOUT                                0.590000   \n","              80/20-HOLDOUT                                0.570000   \n","              90/10-HOLDOUT                                0.570000   \n","              10-FOLD                                      0.574000   \n","pca_d=459     70/30-HOLDOUT                                0.453333   \n","              80/20-HOLDOUT                                0.420000   \n","              90/10-HOLDOUT                                0.500000   \n","              10-FOLD                                      0.488000   \n","noncorr_d=540 70/30-HOLDOUT                                0.506667   \n","              80/20-HOLDOUT                                0.505000   \n","              90/10-HOLDOUT                                0.500000   \n","              10-FOLD                                      0.519000   \n","\n","                                                                    \\\n","                              activation=relu,hidden_layer_sizes=A   \n","dataset       train/test_type                                        \n","normal_d=1764 70/30-HOLDOUT                               0.516667   \n","              80/20-HOLDOUT                               0.525000   \n","              90/10-HOLDOUT                               0.530000   \n","              10-FOLD                                     0.559000   \n","normal_d=900  70/30-HOLDOUT                               0.556667   \n","              80/20-HOLDOUT                               0.625000   \n","              90/10-HOLDOUT                               0.580000   \n","              10-FOLD                                     0.569000   \n","pca_d=459     70/30-HOLDOUT                               0.463333   \n","              80/20-HOLDOUT                               0.420000   \n","              90/10-HOLDOUT                               0.520000   \n","              10-FOLD                                     0.497000   \n","noncorr_d=540 70/30-HOLDOUT                               0.510000   \n","              80/20-HOLDOUT                               0.530000   \n","              90/10-HOLDOUT                               0.510000   \n","              10-FOLD                                     0.531000   \n","\n","                                                                     \\\n","                              activation=relu,hidden_layer_sizes=AT   \n","dataset       train/test_type                                         \n","normal_d=1764 70/30-HOLDOUT                                0.533333   \n","              80/20-HOLDOUT                                0.525000   \n","              90/10-HOLDOUT                                0.520000   \n","              10-FOLD                                      0.560000   \n","normal_d=900  70/30-HOLDOUT                                0.526667   \n","              80/20-HOLDOUT                                0.600000   \n","              90/10-HOLDOUT                                0.600000   \n","              10-FOLD                                      0.574000   \n","pca_d=459     70/30-HOLDOUT                                0.450000   \n","              80/20-HOLDOUT                                0.490000   \n","              90/10-HOLDOUT                                0.530000   \n","              10-FOLD                                      0.502000   \n","noncorr_d=540 70/30-HOLDOUT                                0.540000   \n","              80/20-HOLDOUT                                0.500000   \n","              90/10-HOLDOUT                                0.540000   \n","              10-FOLD                                      0.551000   \n","\n","                                                                    \n","                              activation=relu,hidden_layer_sizes=T  \n","dataset       train/test_type                                       \n","normal_d=1764 70/30-HOLDOUT                               0.513333  \n","              80/20-HOLDOUT                               0.525000  \n","              90/10-HOLDOUT                               0.530000  \n","              10-FOLD                                     0.563000  \n","normal_d=900  70/30-HOLDOUT                               0.546667  \n","              80/20-HOLDOUT                               0.605000  \n","              90/10-HOLDOUT                               0.620000  \n","              10-FOLD                                     0.581000  \n","pca_d=459     70/30-HOLDOUT                               0.453333  \n","              80/20-HOLDOUT                               0.480000  \n","              90/10-HOLDOUT                               0.510000  \n","              10-FOLD                                     0.526000  \n","noncorr_d=540 70/30-HOLDOUT                               0.510000  \n","              80/20-HOLDOUT                               0.520000  \n","              90/10-HOLDOUT                               0.480000  \n","              10-FOLD                                     0.530000  "],"text/html":["\n","  <div id=\"df-c2bf1fbc-eac2-4de7-a242-8cd52c5458dd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"5\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=O</th>\n","      <th>activation=relu,hidden_layer_sizes=OA</th>\n","      <th>activation=relu,hidden_layer_sizes=A</th>\n","      <th>activation=relu,hidden_layer_sizes=AT</th>\n","      <th>activation=relu,hidden_layer_sizes=T</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.436667</td>\n","      <td>0.533333</td>\n","      <td>0.516667</td>\n","      <td>0.533333</td>\n","      <td>0.513333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.435000</td>\n","      <td>0.545000</td>\n","      <td>0.525000</td>\n","      <td>0.525000</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.540000</td>\n","      <td>0.550000</td>\n","      <td>0.530000</td>\n","      <td>0.520000</td>\n","      <td>0.530000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.463000</td>\n","      <td>0.570000</td>\n","      <td>0.559000</td>\n","      <td>0.560000</td>\n","      <td>0.563000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.463333</td>\n","      <td>0.590000</td>\n","      <td>0.556667</td>\n","      <td>0.526667</td>\n","      <td>0.546667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.520000</td>\n","      <td>0.570000</td>\n","      <td>0.625000</td>\n","      <td>0.600000</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.540000</td>\n","      <td>0.570000</td>\n","      <td>0.580000</td>\n","      <td>0.600000</td>\n","      <td>0.620000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.480000</td>\n","      <td>0.574000</td>\n","      <td>0.569000</td>\n","      <td>0.574000</td>\n","      <td>0.581000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.323333</td>\n","      <td>0.453333</td>\n","      <td>0.463333</td>\n","      <td>0.450000</td>\n","      <td>0.453333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.365000</td>\n","      <td>0.420000</td>\n","      <td>0.420000</td>\n","      <td>0.490000</td>\n","      <td>0.480000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.440000</td>\n","      <td>0.500000</td>\n","      <td>0.520000</td>\n","      <td>0.530000</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.454000</td>\n","      <td>0.488000</td>\n","      <td>0.497000</td>\n","      <td>0.502000</td>\n","      <td>0.526000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.460000</td>\n","      <td>0.506667</td>\n","      <td>0.510000</td>\n","      <td>0.540000</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.410000</td>\n","      <td>0.505000</td>\n","      <td>0.530000</td>\n","      <td>0.500000</td>\n","      <td>0.520000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.490000</td>\n","      <td>0.500000</td>\n","      <td>0.510000</td>\n","      <td>0.540000</td>\n","      <td>0.480000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.454000</td>\n","      <td>0.519000</td>\n","      <td>0.531000</td>\n","      <td>0.551000</td>\n","      <td>0.530000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2bf1fbc-eac2-4de7-a242-8cd52c5458dd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c2bf1fbc-eac2-4de7-a242-8cd52c5458dd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2bf1fbc-eac2-4de7-a242-8cd52c5458dd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df_acc_mlp_hls.to_csv(path_to_accuracies+f'{classifier.name}_hls_accuracies.csv',index=True)"],"metadata":{"id":"sJFNxR5MxqZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_acc_mlp_hls.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"1erotnUjw6SG","executionInfo":{"status":"ok","timestamp":1670956251311,"user_tz":180,"elapsed":376,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"035c88eb-c17d-41e4-a2d2-0e9a22cdaf0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       MLP  \\\n","      activation=relu,hidden_layer_sizes=O   \n","count                            16.000000   \n","mean                              0.454646   \n","std                               0.057216   \n","min                               0.323333   \n","25%                               0.436250   \n","50%                               0.457000   \n","75%                               0.482500   \n","max                               0.540000   \n","\n","                                             \\\n","      activation=relu,hidden_layer_sizes=OA   \n","count                             16.000000   \n","mean                               0.524646   \n","std                                0.047149   \n","min                                0.420000   \n","25%                                0.500000   \n","50%                                0.526167   \n","75%                                0.570000   \n","max                                0.590000   \n","\n","                                            \\\n","      activation=relu,hidden_layer_sizes=A   \n","count                            16.000000   \n","mean                              0.527667   \n","std                               0.047080   \n","min                               0.420000   \n","25%                               0.510000   \n","50%                               0.527500   \n","75%                               0.557250   \n","max                               0.625000   \n","\n","                                             \\\n","      activation=relu,hidden_layer_sizes=AT   \n","count                             16.000000   \n","mean                               0.533875   \n","std                                0.039045   \n","min                                0.450000   \n","25%                                0.515500   \n","50%                                0.531667   \n","75%                                0.553250   \n","max                                0.600000   \n","\n","                                            \n","      activation=relu,hidden_layer_sizes=T  \n","count                            16.000000  \n","mean                              0.530833  \n","std                               0.044556  \n","min                               0.453333  \n","25%                               0.510000  \n","50%                               0.525500  \n","75%                               0.550750  \n","max                               0.620000  "],"text/html":["\n","  <div id=\"df-bec5cbaa-1711-42af-9656-cc393ac34650\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"5\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=O</th>\n","      <th>activation=relu,hidden_layer_sizes=OA</th>\n","      <th>activation=relu,hidden_layer_sizes=A</th>\n","      <th>activation=relu,hidden_layer_sizes=AT</th>\n","      <th>activation=relu,hidden_layer_sizes=T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.454646</td>\n","      <td>0.524646</td>\n","      <td>0.527667</td>\n","      <td>0.533875</td>\n","      <td>0.530833</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.057216</td>\n","      <td>0.047149</td>\n","      <td>0.047080</td>\n","      <td>0.039045</td>\n","      <td>0.044556</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.323333</td>\n","      <td>0.420000</td>\n","      <td>0.420000</td>\n","      <td>0.450000</td>\n","      <td>0.453333</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.436250</td>\n","      <td>0.500000</td>\n","      <td>0.510000</td>\n","      <td>0.515500</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.457000</td>\n","      <td>0.526167</td>\n","      <td>0.527500</td>\n","      <td>0.531667</td>\n","      <td>0.525500</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.482500</td>\n","      <td>0.570000</td>\n","      <td>0.557250</td>\n","      <td>0.553250</td>\n","      <td>0.550750</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.540000</td>\n","      <td>0.590000</td>\n","      <td>0.625000</td>\n","      <td>0.600000</td>\n","      <td>0.620000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec5cbaa-1711-42af-9656-cc393ac34650')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bec5cbaa-1711-42af-9656-cc393ac34650 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bec5cbaa-1711-42af-9656-cc393ac34650');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["stats.friedmanchisquare(*[df_acc_mlp_hls[col] for col in df_acc_mlp_hls.columns])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_U5_ILZ-xfnL","executionInfo":{"status":"ok","timestamp":1670956634207,"user_tz":180,"elapsed":356,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"a6c3a1ec-0dba-4900-e531-6d09d9ea09ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FriedmanchisquareResult(statistic=25.440514469453397, pvalue=4.102274603642946e-05)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["nemenyi_p = sp.posthoc_nemenyi_friedman(np.array([df_acc_mlp_hls[col] for col in df_acc_mlp_hls.columns]).T)\n","nemenyi_p.index = [col for col in df_acc_mlp_hls.columns]\n","nemenyi_p.columns = [col for col in df_acc_mlp_hls.columns]\n","nemenyi_p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"DkIBpqMWxw4m","executionInfo":{"status":"ok","timestamp":1670956697953,"user_tz":180,"elapsed":370,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"1745dadb-ce5a-4626-e7b2-5a9c93a617d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              (MLP, activation=relu,hidden_layer_sizes=O)  \\\n","(MLP, activation=relu,hidden_layer_sizes=O)                                      1.000000   \n","(MLP, activation=relu,hidden_layer_sizes=OA)                                     0.002591   \n","(MLP, activation=relu,hidden_layer_sizes=A)                                      0.001000   \n","(MLP, activation=relu,hidden_layer_sizes=AT)                                     0.001000   \n","(MLP, activation=relu,hidden_layer_sizes=T)                                      0.001000   \n","\n","                                              (MLP, activation=relu,hidden_layer_sizes=OA)  \\\n","(MLP, activation=relu,hidden_layer_sizes=O)                                       0.002591   \n","(MLP, activation=relu,hidden_layer_sizes=OA)                                      1.000000   \n","(MLP, activation=relu,hidden_layer_sizes=A)                                       0.900000   \n","(MLP, activation=relu,hidden_layer_sizes=AT)                                      0.900000   \n","(MLP, activation=relu,hidden_layer_sizes=T)                                       0.900000   \n","\n","                                              (MLP, activation=relu,hidden_layer_sizes=A)  \\\n","(MLP, activation=relu,hidden_layer_sizes=O)                                         0.001   \n","(MLP, activation=relu,hidden_layer_sizes=OA)                                        0.900   \n","(MLP, activation=relu,hidden_layer_sizes=A)                                         1.000   \n","(MLP, activation=relu,hidden_layer_sizes=AT)                                        0.900   \n","(MLP, activation=relu,hidden_layer_sizes=T)                                         0.900   \n","\n","                                              (MLP, activation=relu,hidden_layer_sizes=AT)  \\\n","(MLP, activation=relu,hidden_layer_sizes=O)                                          0.001   \n","(MLP, activation=relu,hidden_layer_sizes=OA)                                         0.900   \n","(MLP, activation=relu,hidden_layer_sizes=A)                                          0.900   \n","(MLP, activation=relu,hidden_layer_sizes=AT)                                         1.000   \n","(MLP, activation=relu,hidden_layer_sizes=T)                                          0.900   \n","\n","                                              (MLP, activation=relu,hidden_layer_sizes=T)  \n","(MLP, activation=relu,hidden_layer_sizes=O)                                         0.001  \n","(MLP, activation=relu,hidden_layer_sizes=OA)                                        0.900  \n","(MLP, activation=relu,hidden_layer_sizes=A)                                         0.900  \n","(MLP, activation=relu,hidden_layer_sizes=AT)                                        0.900  \n","(MLP, activation=relu,hidden_layer_sizes=T)                                         1.000  "],"text/html":["\n","  <div id=\"df-3b2d311f-f304-45a8-bfb2-dbda0b37b340\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=O)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=A)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=AT)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=T)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=O)</th>\n","      <td>1.000000</td>\n","      <td>0.002591</td>\n","      <td>0.001</td>\n","      <td>0.001</td>\n","      <td>0.001</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA)</th>\n","      <td>0.002591</td>\n","      <td>1.000000</td>\n","      <td>0.900</td>\n","      <td>0.900</td>\n","      <td>0.900</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=A)</th>\n","      <td>0.001000</td>\n","      <td>0.900000</td>\n","      <td>1.000</td>\n","      <td>0.900</td>\n","      <td>0.900</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=AT)</th>\n","      <td>0.001000</td>\n","      <td>0.900000</td>\n","      <td>0.900</td>\n","      <td>1.000</td>\n","      <td>0.900</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=T)</th>\n","      <td>0.001000</td>\n","      <td>0.900000</td>\n","      <td>0.900</td>\n","      <td>0.900</td>\n","      <td>1.000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b2d311f-f304-45a8-bfb2-dbda0b37b340')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b2d311f-f304-45a8-bfb2-dbda0b37b340 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b2d311f-f304-45a8-bfb2-dbda0b37b340');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["## Max iterations"],"metadata":{"id":"4ssvzKUMwd2g"}},{"cell_type":"code","source":["params = {'activation':['relu'],'hidden_layer_sizes':['OA'],\n","          'max_iter':[100,1000,5000]}\n","df_acc_mlp_it = df_accuracies(X_all,y_all,names_datasets,scalers,classifier,\n","              hyperparams=params,verbose=True)\n","df_acc_mlp_it"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l8slYfDCwgFq","executionInfo":{"status":"ok","timestamp":1670957629706,"user_tz":180,"elapsed":878317,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"193c4836-bea0-4ee6-e255-ddfadebe9b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.507\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.537\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.495\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.515\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.545\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.540\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.540\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.564\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.568\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.576\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.523\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.547\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.557\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.600\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.605\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.605\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.610\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.590\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.610\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.576\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.571\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.569\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.367\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.463\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.423\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.475\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.455\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.500\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.510\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.430\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.490\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.496\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.504\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.483\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.517\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.487\n","\n","80/20-HOLDOUT:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.510\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.520\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=100'): 0.542\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000'): 0.543\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=5000'): 0.519\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                                             MLP  \\\n","                              activation=relu,hidden_layer_sizes=OA,max_iter=100   \n","dataset       train/test_type                                                      \n","normal_d=1764 70/30-HOLDOUT                                             0.520000   \n","              80/20-HOLDOUT                                             0.495000   \n","              90/10-HOLDOUT                                             0.540000   \n","              10-FOLD                                                   0.564000   \n","normal_d=900  70/30-HOLDOUT                                             0.523333   \n","              80/20-HOLDOUT                                             0.600000   \n","              90/10-HOLDOUT                                             0.610000   \n","              10-FOLD                                                   0.576000   \n","pca_d=459     70/30-HOLDOUT                                             0.366667   \n","              80/20-HOLDOUT                                             0.475000   \n","              90/10-HOLDOUT                                             0.510000   \n","              10-FOLD                                                   0.496000   \n","noncorr_d=540 70/30-HOLDOUT                                             0.490000   \n","              80/20-HOLDOUT                                             0.490000   \n","              90/10-HOLDOUT                                             0.530000   \n","              10-FOLD                                                   0.542000   \n","\n","                                                                                   \\\n","                              activation=relu,hidden_layer_sizes=OA,max_iter=1000   \n","dataset       train/test_type                                                       \n","normal_d=1764 70/30-HOLDOUT                                             0.506667    \n","              80/20-HOLDOUT                                             0.515000    \n","              90/10-HOLDOUT                                             0.540000    \n","              10-FOLD                                                   0.568000    \n","normal_d=900  70/30-HOLDOUT                                             0.546667    \n","              80/20-HOLDOUT                                             0.605000    \n","              90/10-HOLDOUT                                             0.590000    \n","              10-FOLD                                                   0.571000    \n","pca_d=459     70/30-HOLDOUT                                             0.463333    \n","              80/20-HOLDOUT                                             0.455000    \n","              90/10-HOLDOUT                                             0.430000    \n","              10-FOLD                                                   0.504000    \n","noncorr_d=540 70/30-HOLDOUT                                             0.516667    \n","              80/20-HOLDOUT                                             0.490000    \n","              90/10-HOLDOUT                                             0.530000    \n","              10-FOLD                                                   0.543000    \n","\n","                                                                                   \n","                              activation=relu,hidden_layer_sizes=OA,max_iter=5000  \n","dataset       train/test_type                                                      \n","normal_d=1764 70/30-HOLDOUT                                             0.536667   \n","              80/20-HOLDOUT                                             0.545000   \n","              90/10-HOLDOUT                                             0.540000   \n","              10-FOLD                                                   0.576000   \n","normal_d=900  70/30-HOLDOUT                                             0.556667   \n","              80/20-HOLDOUT                                             0.605000   \n","              90/10-HOLDOUT                                             0.610000   \n","              10-FOLD                                                   0.569000   \n","pca_d=459     70/30-HOLDOUT                                             0.423333   \n","              80/20-HOLDOUT                                             0.500000   \n","              90/10-HOLDOUT                                             0.490000   \n","              10-FOLD                                                   0.483000   \n","noncorr_d=540 70/30-HOLDOUT                                             0.486667   \n","              80/20-HOLDOUT                                             0.510000   \n","              90/10-HOLDOUT                                             0.520000   \n","              10-FOLD                                                   0.519000   "],"text/html":["\n","  <div id=\"df-8d7e756f-79f7-4444-8209-d4ce2ed9e623\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=100</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=5000</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.520000</td>\n","      <td>0.506667</td>\n","      <td>0.536667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.495000</td>\n","      <td>0.515000</td>\n","      <td>0.545000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.540000</td>\n","      <td>0.540000</td>\n","      <td>0.540000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.564000</td>\n","      <td>0.568000</td>\n","      <td>0.576000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.523333</td>\n","      <td>0.546667</td>\n","      <td>0.556667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.600000</td>\n","      <td>0.605000</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.610000</td>\n","      <td>0.590000</td>\n","      <td>0.610000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.576000</td>\n","      <td>0.571000</td>\n","      <td>0.569000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.366667</td>\n","      <td>0.463333</td>\n","      <td>0.423333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.475000</td>\n","      <td>0.455000</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.510000</td>\n","      <td>0.430000</td>\n","      <td>0.490000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.496000</td>\n","      <td>0.504000</td>\n","      <td>0.483000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.490000</td>\n","      <td>0.516667</td>\n","      <td>0.486667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.490000</td>\n","      <td>0.490000</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.530000</td>\n","      <td>0.530000</td>\n","      <td>0.520000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.542000</td>\n","      <td>0.543000</td>\n","      <td>0.519000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d7e756f-79f7-4444-8209-d4ce2ed9e623')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d7e756f-79f7-4444-8209-d4ce2ed9e623 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d7e756f-79f7-4444-8209-d4ce2ed9e623');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["df_acc_mlp_it.to_csv(path_to_accuracies+f'{classifier.name}_it_accuracies.csv',index=True)"],"metadata":{"id":"J_bHryMwxtJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_acc_mlp_it.describe()"],"metadata":{"id":"fVK9pbSZxGKJ","executionInfo":{"status":"ok","timestamp":1670957649086,"user_tz":180,"elapsed":399,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"colab":{"base_uri":"https://localhost:8080/","height":396},"outputId":"50ab99c5-0b32-42bb-9838-334ac8e44f75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     MLP  \\\n","      activation=relu,hidden_layer_sizes=OA,max_iter=100   \n","count                                          16.000000   \n","mean                                            0.520500   \n","std                                             0.057271   \n","min                                             0.366667   \n","25%                                             0.493750   \n","50%                                             0.521667   \n","75%                                             0.547500   \n","max                                             0.610000   \n","\n","                                                           \\\n","      activation=relu,hidden_layer_sizes=OA,max_iter=1000   \n","count                                          16.000000    \n","mean                                            0.523396    \n","std                                             0.048643    \n","min                                             0.430000    \n","25%                                             0.500500    \n","50%                                             0.523333    \n","75%                                             0.552000    \n","max                                             0.605000    \n","\n","                                                           \n","      activation=relu,hidden_layer_sizes=OA,max_iter=5000  \n","count                                          16.000000   \n","mean                                            0.529396   \n","std                                             0.048526   \n","min                                             0.423333   \n","25%                                             0.497500   \n","50%                                             0.528333   \n","75%                                             0.559750   \n","max                                             0.610000   "],"text/html":["\n","  <div id=\"df-3321a47b-74bd-4dce-9f4a-14119964cccd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=100</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=5000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.520500</td>\n","      <td>0.523396</td>\n","      <td>0.529396</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.057271</td>\n","      <td>0.048643</td>\n","      <td>0.048526</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.366667</td>\n","      <td>0.430000</td>\n","      <td>0.423333</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.493750</td>\n","      <td>0.500500</td>\n","      <td>0.497500</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.521667</td>\n","      <td>0.523333</td>\n","      <td>0.528333</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.547500</td>\n","      <td>0.552000</td>\n","      <td>0.559750</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.610000</td>\n","      <td>0.605000</td>\n","      <td>0.610000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3321a47b-74bd-4dce-9f4a-14119964cccd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3321a47b-74bd-4dce-9f4a-14119964cccd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3321a47b-74bd-4dce-9f4a-14119964cccd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["stats.friedmanchisquare(*[df_acc_mlp_it[col] for col in df_acc_mlp_it.columns])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-YSEvDT4g3F","executionInfo":{"status":"ok","timestamp":1670958466146,"user_tz":180,"elapsed":26,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"9dddf38b-17e3-4f56-e251-38c8d4e0dd6a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FriedmanchisquareResult(statistic=0.75, pvalue=0.6872892787909721)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["## Initial learning rate"],"metadata":{"id":"b0I3n4CDwgej"}},{"cell_type":"code","source":["params = {'activation':['relu'],'hidden_layer_sizes':['OA'],\n","          'max_iter':[1000],'learning_rate_init':[0.001,0.01,0.1]}\n","df_acc_mlp_lr = df_accuracies(X_all,y_all,names_datasets,scalers,classifier,\n","              hyperparams=params,verbose=True)\n","df_acc_mlp_lr"],"metadata":{"id":"bHkMNGITwf_C","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1670958358320,"user_tz":180,"elapsed":646212,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"190bb3f9-15b2-460b-a5a1-1c2d30699a9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.530\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.537\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.487\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.525\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.475\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.465\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.560\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.550\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.560\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.577\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.552\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.521\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.537\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.527\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.503\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.600\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.585\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.595\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.580\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.620\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.610\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.574\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.558\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.523\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.463\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.487\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.470\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.425\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.450\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.460\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.490\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.510\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.466\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.512\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.468\n","\n","70/30-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.507\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.493\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.423\n","\n","80/20-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.485\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.510\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.405\n","\n","90/10-HOLDOUT:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.450\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.520\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.360\n","\n","10-FOLD:\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001'): 0.534\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01'): 0.522\n","\tAccuracy('MLP', 'activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1'): 0.483\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                                                                       MLP  \\\n","                              activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001   \n","dataset       train/test_type                                                                                \n","normal_d=1764 70/30-HOLDOUT                                             0.530000                             \n","              80/20-HOLDOUT                                             0.525000                             \n","              90/10-HOLDOUT                                             0.560000                             \n","              10-FOLD                                                   0.577000                             \n","normal_d=900  70/30-HOLDOUT                                             0.536667                             \n","              80/20-HOLDOUT                                             0.600000                             \n","              90/10-HOLDOUT                                             0.580000                             \n","              10-FOLD                                                   0.574000                             \n","pca_d=459     70/30-HOLDOUT                                             0.463333                             \n","              80/20-HOLDOUT                                             0.425000                             \n","              90/10-HOLDOUT                                             0.460000                             \n","              10-FOLD                                                   0.466000                             \n","noncorr_d=540 70/30-HOLDOUT                                             0.506667                             \n","              80/20-HOLDOUT                                             0.485000                             \n","              90/10-HOLDOUT                                             0.450000                             \n","              10-FOLD                                                   0.534000                             \n","\n","                                                                                                           \\\n","                              activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01   \n","dataset       train/test_type                                                                               \n","normal_d=1764 70/30-HOLDOUT                                             0.536667                            \n","              80/20-HOLDOUT                                             0.475000                            \n","              90/10-HOLDOUT                                             0.550000                            \n","              10-FOLD                                                   0.552000                            \n","normal_d=900  70/30-HOLDOUT                                             0.526667                            \n","              80/20-HOLDOUT                                             0.585000                            \n","              90/10-HOLDOUT                                             0.620000                            \n","              10-FOLD                                                   0.558000                            \n","pca_d=459     70/30-HOLDOUT                                             0.486667                            \n","              80/20-HOLDOUT                                             0.520000                            \n","              90/10-HOLDOUT                                             0.490000                            \n","              10-FOLD                                                   0.512000                            \n","noncorr_d=540 70/30-HOLDOUT                                             0.493333                            \n","              80/20-HOLDOUT                                             0.510000                            \n","              90/10-HOLDOUT                                             0.520000                            \n","              10-FOLD                                                   0.522000                            \n","\n","                                                                                                          \n","                              activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1  \n","dataset       train/test_type                                                                             \n","normal_d=1764 70/30-HOLDOUT                                             0.486667                          \n","              80/20-HOLDOUT                                             0.465000                          \n","              90/10-HOLDOUT                                             0.560000                          \n","              10-FOLD                                                   0.521000                          \n","normal_d=900  70/30-HOLDOUT                                             0.503333                          \n","              80/20-HOLDOUT                                             0.595000                          \n","              90/10-HOLDOUT                                             0.610000                          \n","              10-FOLD                                                   0.523000                          \n","pca_d=459     70/30-HOLDOUT                                             0.470000                          \n","              80/20-HOLDOUT                                             0.450000                          \n","              90/10-HOLDOUT                                             0.510000                          \n","              10-FOLD                                                   0.468000                          \n","noncorr_d=540 70/30-HOLDOUT                                             0.423333                          \n","              80/20-HOLDOUT                                             0.405000                          \n","              90/10-HOLDOUT                                             0.360000                          \n","              10-FOLD                                                   0.483000                          "],"text/html":["\n","  <div id=\"df-25a25b88-d4f4-4c8f-9733-c3be58475ce7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1</th>\n","    </tr>\n","    <tr>\n","      <th>dataset</th>\n","      <th>train/test_type</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=1764</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.530000</td>\n","      <td>0.536667</td>\n","      <td>0.486667</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.525000</td>\n","      <td>0.475000</td>\n","      <td>0.465000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.560000</td>\n","      <td>0.550000</td>\n","      <td>0.560000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.577000</td>\n","      <td>0.552000</td>\n","      <td>0.521000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">normal_d=900</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.536667</td>\n","      <td>0.526667</td>\n","      <td>0.503333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.600000</td>\n","      <td>0.585000</td>\n","      <td>0.595000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.580000</td>\n","      <td>0.620000</td>\n","      <td>0.610000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.574000</td>\n","      <td>0.558000</td>\n","      <td>0.523000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">pca_d=459</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.463333</td>\n","      <td>0.486667</td>\n","      <td>0.470000</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.425000</td>\n","      <td>0.520000</td>\n","      <td>0.450000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.460000</td>\n","      <td>0.490000</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.466000</td>\n","      <td>0.512000</td>\n","      <td>0.468000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">noncorr_d=540</th>\n","      <th>70/30-HOLDOUT</th>\n","      <td>0.506667</td>\n","      <td>0.493333</td>\n","      <td>0.423333</td>\n","    </tr>\n","    <tr>\n","      <th>80/20-HOLDOUT</th>\n","      <td>0.485000</td>\n","      <td>0.510000</td>\n","      <td>0.405000</td>\n","    </tr>\n","    <tr>\n","      <th>90/10-HOLDOUT</th>\n","      <td>0.450000</td>\n","      <td>0.520000</td>\n","      <td>0.360000</td>\n","    </tr>\n","    <tr>\n","      <th>10-FOLD</th>\n","      <td>0.534000</td>\n","      <td>0.522000</td>\n","      <td>0.483000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25a25b88-d4f4-4c8f-9733-c3be58475ce7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-25a25b88-d4f4-4c8f-9733-c3be58475ce7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-25a25b88-d4f4-4c8f-9733-c3be58475ce7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["df_acc_mlp_lr.to_csv(path_to_accuracies+f'{classifier.name}_lr_accuracies.csv',index=True)"],"metadata":{"id":"e6ol7ttexvbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_acc_mlp_lr.describe()"],"metadata":{"id":"6S1mkHwXxUPz","colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"status":"ok","timestamp":1670958369503,"user_tz":180,"elapsed":29,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"4b226418-0bf3-41b7-aeac-c6634db4e6a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                               MLP  \\\n","      activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001   \n","count                                          16.000000                             \n","mean                                            0.517042                             \n","std                                             0.053714                             \n","min                                             0.425000                             \n","25%                                             0.465333                             \n","50%                                             0.527500                             \n","75%                                             0.563500                             \n","max                                             0.600000                             \n","\n","                                                                                   \\\n","      activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01   \n","count                                          16.000000                            \n","mean                                            0.528583                            \n","std                                             0.037993                            \n","min                                             0.475000                            \n","25%                                             0.505833                            \n","50%                                             0.521000                            \n","75%                                             0.550500                            \n","max                                             0.620000                            \n","\n","                                                                                  \n","      activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1  \n","count                                          16.000000                          \n","mean                                            0.489583                          \n","std                                             0.065670                          \n","min                                             0.360000                          \n","25%                                             0.461250                          \n","50%                                             0.484833                          \n","75%                                             0.521500                          \n","max                                             0.610000                          "],"text/html":["\n","  <div id=\"df-d17191ab-c761-41ba-89ef-95702b89926e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">MLP</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01</th>\n","      <th>activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","      <td>16.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.517042</td>\n","      <td>0.528583</td>\n","      <td>0.489583</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.053714</td>\n","      <td>0.037993</td>\n","      <td>0.065670</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.425000</td>\n","      <td>0.475000</td>\n","      <td>0.360000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.465333</td>\n","      <td>0.505833</td>\n","      <td>0.461250</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.527500</td>\n","      <td>0.521000</td>\n","      <td>0.484833</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.563500</td>\n","      <td>0.550500</td>\n","      <td>0.521500</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.600000</td>\n","      <td>0.620000</td>\n","      <td>0.610000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d17191ab-c761-41ba-89ef-95702b89926e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d17191ab-c761-41ba-89ef-95702b89926e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d17191ab-c761-41ba-89ef-95702b89926e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["stats.friedmanchisquare(*[df_acc_mlp_lr[col] for col in df_acc_mlp_lr.columns])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5xQZmqP4yUj","executionInfo":{"status":"ok","timestamp":1670958500269,"user_tz":180,"elapsed":400,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"7e3bf794-5689-488b-b3ea-c2975627eee4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FriedmanchisquareResult(statistic=5.555555555555555, pvalue=0.06217652402211632)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["nemenyi_p = sp.posthoc_nemenyi_friedman(np.array([df_acc_mlp_lr[col] for col in df_acc_mlp_lr.columns]).T)\n","nemenyi_p.index = [col for col in df_acc_mlp_lr.columns]\n","nemenyi_p.columns = [col for col in df_acc_mlp_lr.columns]\n","nemenyi_p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"P_0zo2Xr41Je","executionInfo":{"status":"ok","timestamp":1670958527105,"user_tz":180,"elapsed":12,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"31747d40-8b30-4790-d30c-a14d265ff357"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    (MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001)  \\\n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           1.000000                                     \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.890699                                     \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.180637                                     \n","\n","                                                    (MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01)  \\\n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.890699                                    \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           1.000000                                    \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.069588                                    \n","\n","                                                    (MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1)  \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.180637                                  \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           0.069588                                  \n","(MLP, activation=relu,hidden_layer_sizes=OA,max...                                           1.000000                                  "],"text/html":["\n","  <div id=\"df-0fcc53ff-a878-4d8f-8efb-4eb12fc91366\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01)</th>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.001)</th>\n","      <td>1.000000</td>\n","      <td>0.890699</td>\n","      <td>0.180637</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.01)</th>\n","      <td>0.890699</td>\n","      <td>1.000000</td>\n","      <td>0.069588</td>\n","    </tr>\n","    <tr>\n","      <th>(MLP, activation=relu,hidden_layer_sizes=OA,max_iter=1000,learning_rate_init=0.1)</th>\n","      <td>0.180637</td>\n","      <td>0.069588</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fcc53ff-a878-4d8f-8efb-4eb12fc91366')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0fcc53ff-a878-4d8f-8efb-4eb12fc91366 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0fcc53ff-a878-4d8f-8efb-4eb12fc91366');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"fiOxDSsRnB80"},"source":["# Bagging"]},{"cell_type":"markdown","metadata":{"id":"a7prtHfOnMoN"},"source":["## kNN, DT, NB and MLP"]},{"cell_type":"code","source":["classifier = Classifier.BAGGING\n","\n","scalers = {'knn':[None]*len(X_all),'dt':[None]*len(X_all),\n","           'nb':[None]*len(X_all),'mlp':['standard','standard',None,'standard']}\n","\n","hyperparams={'knn':{'base_estimator': [KNeighborsClassifier(n_neighbors=3)],\n","                    'n_estimators':[10,20],\n","                    'max_features':[1.0,0.5]},\n","             'dt':{'base_estimator': [DecisionTreeClassifier(max_depth=4)],\n","                   'n_estimators':[10,20],\n","                   'max_features':[1.0,0.5]},\n","             'nb':{'base_estimator': [GaussianNB()],\n","                   'n_estimators':[10,20],\n","                   'max_features':[1.0,0.5]},\n","             'mlp':{'base_estimator': [MLPClassifier(activation='relu',\n","                                                     max_iter=1000,\n","                                                     learning_rate_init=0.001)],\n","                    'n_estimators':[10,20],\n","                    'max_features':[1.0,0.5],\n","                    'base_estimator__hidden_layer_sizes':['OA']}}"],"metadata":{"id":"pJbMGEKgU16R"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U36tUZz36MgX"},"outputs":[],"source":["for base_classifier in ['knn','dt','nb']:\n","    df = df_accuracies(X_all,y_all,names_datasets,scalers[base_classifier],\n","                       classifier,\n","                       hyperparams=hyperparams[base_classifier],verbose=False)\n","    df.to_csv(path_to_accuracies+\\\n","            f'{classifier.name}_{base_classifier}_accuracies.csv',\n","            index=True)"]},{"cell_type":"code","source":["for base_classifier in ['mlp']:\n","    df = df_accuracies(X_all,y_all,names_datasets,scalers[base_classifier],\n","                       classifier,\n","                       hyperparams=hyperparams[base_classifier],verbose=True)\n","    df.to_csv(path_to_accuracies+\\\n","            f'{classifier.name}_{base_classifier}_accuracies.csv',\n","            index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UT2knPI5t7yV","outputId":"da8da5f9-5230-42df-bcf4-6cfa9d6ae4ee"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","70/30-HOLDOUT:\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.513\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.540\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.540\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.537\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.510\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.530\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.535\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.540\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.520\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.540\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.550\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.550\n","\n","10-FOLD:\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.570\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=10,max_features=0.5,base_estimator__hidden_layer_sizes=OA'): 0.578\n","\tAccuracy('BAGGING', 'base_estimator=MLPClassifier(max_iter=1000),n_estimators=20,max_features=1.0,base_estimator__hidden_layer_sizes=OA'): 0.581\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"D6C9u5tZtVoe"},"source":["# Boosting"]},{"cell_type":"markdown","metadata":{"id":"0tOTpmJ1tVoi"},"source":["## DT and NB"]},{"cell_type":"code","source":["classifier = Classifier.BOOSTING\n","\n","scalers = {'knn':[None]*len(X_all),'dt':[None]*len(X_all),\n","           'nb':[None]*len(X_all),'mlp':['standard','standard',None,'standard']}\n","\n","hyperparams={'dt':{'base_estimator': [DecisionTreeClassifier(max_depth=4)],\n","                   'n_estimators':[10,20]},\n","             'nb':{'base_estimator': [GaussianNB()],\n","                   'n_estimators':[10,20]}}"],"metadata":{"id":"x1itpPYdUnxu","executionInfo":{"status":"ok","timestamp":1670978471690,"user_tz":180,"elapsed":424,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":692147,"status":"ok","timestamp":1670979164231,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"WGYGVAbutVon","outputId":"9bc2517b-15a6-470c-a52a-f3e8e18b01a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.283\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.327\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.355\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.330\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.270\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.240\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.330\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.319\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.383\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.297\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.300\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.355\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.290\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.340\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.339\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.339\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.300\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.280\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.235\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.195\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.310\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.270\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.297\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.298\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.277\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.320\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.315\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.310\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.380\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.310\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=10'): 0.321\n","\tAccuracy('BOOSTING', 'base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=20'): 0.323\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.317\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.363\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.320\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.220\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.270\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.160\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.241\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.256\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.340\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.217\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.330\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.290\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.280\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.190\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.274\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.262\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.217\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.233\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.245\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.220\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.280\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.300\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.223\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.253\n","\n","70/30-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.270\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.277\n","\n","80/20-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.300\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.345\n","\n","90/10-HOLDOUT:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.360\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.260\n","\n","10-FOLD:\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=10'): 0.253\n","\tAccuracy('BOOSTING', 'base_estimator=GaussianNB(),n_estimators=20'): 0.271\n"]}],"source":["for base_classifier in ['dt','nb']:\n","    df = df_accuracies(X_all,y_all,names_datasets,scalers[base_classifier],\n","                       classifier,\n","                       hyperparams=hyperparams[base_classifier],verbose=True)\n","    df.to_csv(path_to_accuracies+\\\n","            f'{classifier.name}_{base_classifier}_accuracies.csv',\n","            index=True)"]},{"cell_type":"markdown","metadata":{"id":"Xot8sYQxKQSk"},"source":["# Random forest"]},{"cell_type":"code","source":["classifier = Classifier.RANDOM_FOREST\n","\n","hyperparams={'n_estimators':[10,100],'criterion':['gini', 'entropy']}\n","\n","scalers = [None]*len(X_all)"],"metadata":{"id":"1N2w7UfiUrmD","executionInfo":{"status":"ok","timestamp":1670979525820,"user_tz":180,"elapsed":312,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388437,"status":"ok","timestamp":1670979919357,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"},"user_tz":180},"id":"9KL_UviTKTaE","outputId":"ea4ba306-3709-4707-a9e8-e0fe619dc57d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","70/30-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.370\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.390\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.483\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.480\n","\n","80/20-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.385\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.355\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.530\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.570\n","\n","90/10-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.370\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.420\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.590\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.520\n","\n","10-FOLD:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.361\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.362\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.528\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.531\n","\n","70/30-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.357\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.347\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.510\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.510\n","\n","80/20-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.395\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.415\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.610\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.590\n","\n","90/10-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.430\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.400\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.600\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.580\n","\n","10-FOLD:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.404\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.409\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.542\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.532\n","\n","70/30-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.247\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.283\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.363\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.327\n","\n","80/20-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.305\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.250\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.400\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.405\n","\n","90/10-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.330\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.240\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.450\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.430\n","\n","10-FOLD:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.269\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.303\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.387\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.411\n","\n","70/30-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.323\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.363\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.450\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.450\n","\n","80/20-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.340\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.340\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.530\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.510\n","\n","90/10-HOLDOUT:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.320\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.330\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.500\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.510\n","\n","10-FOLD:\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=gini'): 0.358\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=10,criterion=entropy'): 0.348\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=gini'): 0.492\n","\tAccuracy('RANDOM_FOREST', 'n_estimators=100,criterion=entropy'): 0.501\n"]}],"source":["df = df_accuracies(X_all,y_all,names_datasets,scalers,\n","                   classifier,\n","                   hyperparams=hyperparams,verbose=True)\n","df.to_csv(path_to_accuracies+\\\n","        f'{classifier.name}_accuracies.csv',\n","        index=True)"]},{"cell_type":"markdown","metadata":{"id":"wWhPOM4UKULN"},"source":["# Stacking"]},{"cell_type":"code","source":["classifier = Classifier.STACKING\n","\n","hyperparams={'estimators':[[('mlp1',MLPClassifier(activation='logistic',max_iter=700)),\n","                            ('mlp2',MLPClassifier(activation='tanh',max_iter=700)),\n","                            ('mlp3',MLPClassifier(activation='relu',max_iter=700)),\n","                            ('mlp4',MLPClassifier(activation='relu',hidden_layer_sizes=200,max_iter=700)),\n","                            ('mlp5',MLPClassifier(activation='relu',hidden_layer_sizes=300,max_iter=700)),\n","                            ('knn1',KNeighborsClassifier(n_neighbors=1)),\n","                            ('knn2',KNeighborsClassifier(n_neighbors=2)),\n","                            ('knn3',KNeighborsClassifier(n_neighbors=3)),\n","                            ('knn4',KNeighborsClassifier(n_neighbors=4)),\n","                            ('knn5',KNeighborsClassifier(n_neighbors=5))],\n","                           [('mlp1',MLPClassifier(activation='logistic',max_iter=700)),\n","                            ('mlp2',MLPClassifier(activation='tanh',max_iter=700)),\n","                            ('mlp3',MLPClassifier(activation='relu',max_iter=700)),\n","                            ('mlp4',MLPClassifier(activation='logistic',hidden_layer_sizes=200,max_iter=700)),\n","                            ('mlp5',MLPClassifier(activation='tanh',hidden_layer_sizes=200,max_iter=700)),\n","                            ('mlp6',MLPClassifier(activation='relu',hidden_layer_sizes=200,max_iter=700)),\n","                            ('mlp7',MLPClassifier(activation='logistic',hidden_layer_sizes=300,max_iter=700)),\n","                            ('mlp8',MLPClassifier(activation='tanh',hidden_layer_sizes=300,max_iter=700)),\n","                            ('mlp9',MLPClassifier(activation='relu',hidden_layer_sizes=300,max_iter=700)),\n","                            ('knn1',KNeighborsClassifier(n_neighbors=1)),\n","                            ('knn2',KNeighborsClassifier(n_neighbors=2)),\n","                            ('knn3',KNeighborsClassifier(n_neighbors=3)),\n","                            ('knn4',KNeighborsClassifier(n_neighbors=4)),\n","                            ('knn5',KNeighborsClassifier(n_neighbors=5)),\n","                            ('knn6',KNeighborsClassifier(n_neighbors=6)),\n","                            ('knn7',KNeighborsClassifier(n_neighbors=7)),\n","                            ('knn8',KNeighborsClassifier(n_neighbors=8)),\n","                            ('knn9',KNeighborsClassifier(n_neighbors=9)),\n","                            ('knn10',KNeighborsClassifier(n_neighbors=10)),\n","                            ('nb',GaussianNB())]]}\n","\n","scalers = ['standard','standard',None,'standard']"],"metadata":{"id":"gEZgfiCzGF5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-svj0oBBKc6M","executionInfo":{"status":"ok","timestamp":1670340874479,"user_tz":180,"elapsed":5306695,"user":{"displayName":"Bruno Silva","userId":"01771094133195996972"}},"outputId":"32c9675e-f1f6-4de6-8e1d-f1b08da2f702"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 70-train/30-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.993\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.473\n","[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 80-train/20-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.995\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.560\n","[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 90-train/10-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.990\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.500\n","Accuracy (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.573 0.054\n","[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 70-train/30-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.994\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.620\n","[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 80-train/20-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.975\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.630\n","[{'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())]}]\n","[{}]\n","\n","Holdout: 90-train/10-test\n","{'cv': None, 'estimators': [('mlp1', MLPClassifier(activation='logistic', max_iter=700)), ('mlp2', MLPClassifier(activation='tanh', max_iter=700)), ('mlp3', MLPClassifier(max_iter=700)), ('mlp4', MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700)), ('mlp5', MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700)), ('mlp6', MLPClassifier(hidden_layer_sizes=200, max_iter=700)), ('mlp7', MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700)), ('mlp8', MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700)), ('mlp9', MLPClassifier(hidden_layer_sizes=300, max_iter=700)), ('knn1', KNeighborsClassifier(n_neighbors=1)), ('knn2', KNeighborsClassifier(n_neighbors=2)), ('knn3', KNeighborsClassifier(n_neighbors=3)), ('knn4', KNeighborsClassifier(n_neighbors=4)), ('knn5', KNeighborsClassifier()), ('knn6', KNeighborsClassifier(n_neighbors=6)), ('knn7', KNeighborsClassifier(n_neighbors=7)), ('knn8', KNeighborsClassifier(n_neighbors=8)), ('knn9', KNeighborsClassifier(n_neighbors=9)), ('knn10', KNeighborsClassifier(n_neighbors=10)), ('nb', GaussianNB())], 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 500, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'final_estimator': LogisticRegression(max_iter=500), 'n_jobs': None, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'mlp1': MLPClassifier(activation='logistic', max_iter=700), 'mlp2': MLPClassifier(activation='tanh', max_iter=700), 'mlp3': MLPClassifier(max_iter=700), 'mlp4': MLPClassifier(activation='logistic', hidden_layer_sizes=200, max_iter=700), 'mlp5': MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=700), 'mlp6': MLPClassifier(hidden_layer_sizes=200, max_iter=700), 'mlp7': MLPClassifier(activation='logistic', hidden_layer_sizes=300, max_iter=700), 'mlp8': MLPClassifier(activation='tanh', hidden_layer_sizes=300, max_iter=700), 'mlp9': MLPClassifier(hidden_layer_sizes=300, max_iter=700), 'knn1': KNeighborsClassifier(n_neighbors=1), 'knn2': KNeighborsClassifier(n_neighbors=2), 'knn3': KNeighborsClassifier(n_neighbors=3), 'knn4': KNeighborsClassifier(n_neighbors=4), 'knn5': KNeighborsClassifier(), 'knn6': KNeighborsClassifier(n_neighbors=6), 'knn7': KNeighborsClassifier(n_neighbors=7), 'knn8': KNeighborsClassifier(n_neighbors=8), 'knn9': KNeighborsClassifier(n_neighbors=9), 'knn10': KNeighborsClassifier(n_neighbors=10), 'nb': GaussianNB(), 'mlp1__activation': 'logistic', 'mlp1__alpha': 0.0001, 'mlp1__batch_size': 'auto', 'mlp1__beta_1': 0.9, 'mlp1__beta_2': 0.999, 'mlp1__early_stopping': False, 'mlp1__epsilon': 1e-08, 'mlp1__hidden_layer_sizes': (100,), 'mlp1__learning_rate': 'constant', 'mlp1__learning_rate_init': 0.001, 'mlp1__max_fun': 15000, 'mlp1__max_iter': 700, 'mlp1__momentum': 0.9, 'mlp1__n_iter_no_change': 10, 'mlp1__nesterovs_momentum': True, 'mlp1__power_t': 0.5, 'mlp1__random_state': None, 'mlp1__shuffle': True, 'mlp1__solver': 'adam', 'mlp1__tol': 0.0001, 'mlp1__validation_fraction': 0.1, 'mlp1__verbose': False, 'mlp1__warm_start': False, 'mlp2__activation': 'tanh', 'mlp2__alpha': 0.0001, 'mlp2__batch_size': 'auto', 'mlp2__beta_1': 0.9, 'mlp2__beta_2': 0.999, 'mlp2__early_stopping': False, 'mlp2__epsilon': 1e-08, 'mlp2__hidden_layer_sizes': (100,), 'mlp2__learning_rate': 'constant', 'mlp2__learning_rate_init': 0.001, 'mlp2__max_fun': 15000, 'mlp2__max_iter': 700, 'mlp2__momentum': 0.9, 'mlp2__n_iter_no_change': 10, 'mlp2__nesterovs_momentum': True, 'mlp2__power_t': 0.5, 'mlp2__random_state': None, 'mlp2__shuffle': True, 'mlp2__solver': 'adam', 'mlp2__tol': 0.0001, 'mlp2__validation_fraction': 0.1, 'mlp2__verbose': False, 'mlp2__warm_start': False, 'mlp3__activation': 'relu', 'mlp3__alpha': 0.0001, 'mlp3__batch_size': 'auto', 'mlp3__beta_1': 0.9, 'mlp3__beta_2': 0.999, 'mlp3__early_stopping': False, 'mlp3__epsilon': 1e-08, 'mlp3__hidden_layer_sizes': (100,), 'mlp3__learning_rate': 'constant', 'mlp3__learning_rate_init': 0.001, 'mlp3__max_fun': 15000, 'mlp3__max_iter': 700, 'mlp3__momentum': 0.9, 'mlp3__n_iter_no_change': 10, 'mlp3__nesterovs_momentum': True, 'mlp3__power_t': 0.5, 'mlp3__random_state': None, 'mlp3__shuffle': True, 'mlp3__solver': 'adam', 'mlp3__tol': 0.0001, 'mlp3__validation_fraction': 0.1, 'mlp3__verbose': False, 'mlp3__warm_start': False, 'mlp4__activation': 'logistic', 'mlp4__alpha': 0.0001, 'mlp4__batch_size': 'auto', 'mlp4__beta_1': 0.9, 'mlp4__beta_2': 0.999, 'mlp4__early_stopping': False, 'mlp4__epsilon': 1e-08, 'mlp4__hidden_layer_sizes': 200, 'mlp4__learning_rate': 'constant', 'mlp4__learning_rate_init': 0.001, 'mlp4__max_fun': 15000, 'mlp4__max_iter': 700, 'mlp4__momentum': 0.9, 'mlp4__n_iter_no_change': 10, 'mlp4__nesterovs_momentum': True, 'mlp4__power_t': 0.5, 'mlp4__random_state': None, 'mlp4__shuffle': True, 'mlp4__solver': 'adam', 'mlp4__tol': 0.0001, 'mlp4__validation_fraction': 0.1, 'mlp4__verbose': False, 'mlp4__warm_start': False, 'mlp5__activation': 'tanh', 'mlp5__alpha': 0.0001, 'mlp5__batch_size': 'auto', 'mlp5__beta_1': 0.9, 'mlp5__beta_2': 0.999, 'mlp5__early_stopping': False, 'mlp5__epsilon': 1e-08, 'mlp5__hidden_layer_sizes': 200, 'mlp5__learning_rate': 'constant', 'mlp5__learning_rate_init': 0.001, 'mlp5__max_fun': 15000, 'mlp5__max_iter': 700, 'mlp5__momentum': 0.9, 'mlp5__n_iter_no_change': 10, 'mlp5__nesterovs_momentum': True, 'mlp5__power_t': 0.5, 'mlp5__random_state': None, 'mlp5__shuffle': True, 'mlp5__solver': 'adam', 'mlp5__tol': 0.0001, 'mlp5__validation_fraction': 0.1, 'mlp5__verbose': False, 'mlp5__warm_start': False, 'mlp6__activation': 'relu', 'mlp6__alpha': 0.0001, 'mlp6__batch_size': 'auto', 'mlp6__beta_1': 0.9, 'mlp6__beta_2': 0.999, 'mlp6__early_stopping': False, 'mlp6__epsilon': 1e-08, 'mlp6__hidden_layer_sizes': 200, 'mlp6__learning_rate': 'constant', 'mlp6__learning_rate_init': 0.001, 'mlp6__max_fun': 15000, 'mlp6__max_iter': 700, 'mlp6__momentum': 0.9, 'mlp6__n_iter_no_change': 10, 'mlp6__nesterovs_momentum': True, 'mlp6__power_t': 0.5, 'mlp6__random_state': None, 'mlp6__shuffle': True, 'mlp6__solver': 'adam', 'mlp6__tol': 0.0001, 'mlp6__validation_fraction': 0.1, 'mlp6__verbose': False, 'mlp6__warm_start': False, 'mlp7__activation': 'logistic', 'mlp7__alpha': 0.0001, 'mlp7__batch_size': 'auto', 'mlp7__beta_1': 0.9, 'mlp7__beta_2': 0.999, 'mlp7__early_stopping': False, 'mlp7__epsilon': 1e-08, 'mlp7__hidden_layer_sizes': 300, 'mlp7__learning_rate': 'constant', 'mlp7__learning_rate_init': 0.001, 'mlp7__max_fun': 15000, 'mlp7__max_iter': 700, 'mlp7__momentum': 0.9, 'mlp7__n_iter_no_change': 10, 'mlp7__nesterovs_momentum': True, 'mlp7__power_t': 0.5, 'mlp7__random_state': None, 'mlp7__shuffle': True, 'mlp7__solver': 'adam', 'mlp7__tol': 0.0001, 'mlp7__validation_fraction': 0.1, 'mlp7__verbose': False, 'mlp7__warm_start': False, 'mlp8__activation': 'tanh', 'mlp8__alpha': 0.0001, 'mlp8__batch_size': 'auto', 'mlp8__beta_1': 0.9, 'mlp8__beta_2': 0.999, 'mlp8__early_stopping': False, 'mlp8__epsilon': 1e-08, 'mlp8__hidden_layer_sizes': 300, 'mlp8__learning_rate': 'constant', 'mlp8__learning_rate_init': 0.001, 'mlp8__max_fun': 15000, 'mlp8__max_iter': 700, 'mlp8__momentum': 0.9, 'mlp8__n_iter_no_change': 10, 'mlp8__nesterovs_momentum': True, 'mlp8__power_t': 0.5, 'mlp8__random_state': None, 'mlp8__shuffle': True, 'mlp8__solver': 'adam', 'mlp8__tol': 0.0001, 'mlp8__validation_fraction': 0.1, 'mlp8__verbose': False, 'mlp8__warm_start': False, 'mlp9__activation': 'relu', 'mlp9__alpha': 0.0001, 'mlp9__batch_size': 'auto', 'mlp9__beta_1': 0.9, 'mlp9__beta_2': 0.999, 'mlp9__early_stopping': False, 'mlp9__epsilon': 1e-08, 'mlp9__hidden_layer_sizes': 300, 'mlp9__learning_rate': 'constant', 'mlp9__learning_rate_init': 0.001, 'mlp9__max_fun': 15000, 'mlp9__max_iter': 700, 'mlp9__momentum': 0.9, 'mlp9__n_iter_no_change': 10, 'mlp9__nesterovs_momentum': True, 'mlp9__power_t': 0.5, 'mlp9__random_state': None, 'mlp9__shuffle': True, 'mlp9__solver': 'adam', 'mlp9__tol': 0.0001, 'mlp9__validation_fraction': 0.1, 'mlp9__verbose': False, 'mlp9__warm_start': False, 'knn1__algorithm': 'auto', 'knn1__leaf_size': 30, 'knn1__metric': 'minkowski', 'knn1__metric_params': None, 'knn1__n_jobs': None, 'knn1__n_neighbors': 1, 'knn1__p': 2, 'knn1__weights': 'uniform', 'knn2__algorithm': 'auto', 'knn2__leaf_size': 30, 'knn2__metric': 'minkowski', 'knn2__metric_params': None, 'knn2__n_jobs': None, 'knn2__n_neighbors': 2, 'knn2__p': 2, 'knn2__weights': 'uniform', 'knn3__algorithm': 'auto', 'knn3__leaf_size': 30, 'knn3__metric': 'minkowski', 'knn3__metric_params': None, 'knn3__n_jobs': None, 'knn3__n_neighbors': 3, 'knn3__p': 2, 'knn3__weights': 'uniform', 'knn4__algorithm': 'auto', 'knn4__leaf_size': 30, 'knn4__metric': 'minkowski', 'knn4__metric_params': None, 'knn4__n_jobs': None, 'knn4__n_neighbors': 4, 'knn4__p': 2, 'knn4__weights': 'uniform', 'knn5__algorithm': 'auto', 'knn5__leaf_size': 30, 'knn5__metric': 'minkowski', 'knn5__metric_params': None, 'knn5__n_jobs': None, 'knn5__n_neighbors': 5, 'knn5__p': 2, 'knn5__weights': 'uniform', 'knn6__algorithm': 'auto', 'knn6__leaf_size': 30, 'knn6__metric': 'minkowski', 'knn6__metric_params': None, 'knn6__n_jobs': None, 'knn6__n_neighbors': 6, 'knn6__p': 2, 'knn6__weights': 'uniform', 'knn7__algorithm': 'auto', 'knn7__leaf_size': 30, 'knn7__metric': 'minkowski', 'knn7__metric_params': None, 'knn7__n_jobs': None, 'knn7__n_neighbors': 7, 'knn7__p': 2, 'knn7__weights': 'uniform', 'knn8__algorithm': 'auto', 'knn8__leaf_size': 30, 'knn8__metric': 'minkowski', 'knn8__metric_params': None, 'knn8__n_jobs': None, 'knn8__n_neighbors': 8, 'knn8__p': 2, 'knn8__weights': 'uniform', 'knn9__algorithm': 'auto', 'knn9__leaf_size': 30, 'knn9__metric': 'minkowski', 'knn9__metric_params': None, 'knn9__n_jobs': None, 'knn9__n_neighbors': 9, 'knn9__p': 2, 'knn9__weights': 'uniform', 'knn10__algorithm': 'auto', 'knn10__leaf_size': 30, 'knn10__metric': 'minkowski', 'knn10__metric_params': None, 'knn10__n_jobs': None, 'knn10__n_neighbors': 10, 'knn10__p': 2, 'knn10__weights': 'uniform', 'nb__priors': None, 'nb__var_smoothing': 1e-09}\n","\tAccuracy of train set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.996\n","\tAccuracy of test set for this holdout (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.560\n","Accuracy (stacking:estimators=[(mlp1,MLPClassifier(activation=logistic,max_iter=700)),(mlp2,MLPClassifier(activation=tanh,max_iter=700)),(mlp3,MLPClassifier(max_iter=700)),(mlp4,MLPClassifier(activation=logistic,hidden_layer_sizes=200,max_iter=700)),(mlp5,MLPClassifier(activation=tanh,hidden_layer_sizes=200,max_iter=700)),(mlp6,MLPClassifier(hidden_layer_sizes=200,max_iter=700)),(mlp7,MLPClassifier(activation=logistic,hidden_layer_sizes=300,max_iter=700)),(mlp8,MLPClassifier(activation=tanh,hidden_layer_sizes=300,max_iter=700)),(mlp9,MLPClassifier(hidden_layer_sizes=300,max_iter=700)),(knn1,KNeighborsClassifier(n_neighbors=1)),(knn2,KNeighborsClassifier(n_neighbors=2)),(knn3,KNeighborsClassifier(n_neighbors=3)),(knn4,KNeighborsClassifier(n_neighbors=4)),(knn5,KNeighborsClassifier()),(knn6,KNeighborsClassifier(n_neighbors=6)),(knn7,KNeighborsClassifier(n_neighbors=7)),(knn8,KNeighborsClassifier(n_neighbors=8)),(knn9,KNeighborsClassifier(n_neighbors=9)),(knn10,KNeighborsClassifier(n_neighbors=10)),(nb,GaussianNB())]): 0.578 0.054\n"]}],"source":["df = df_accuracies(X_all,y_all,names_datasets,scalers,\n","                    classifier,hyperparams=hyperparams,verbose=True)\n","df.to_csv(path_to_accuracies+\\\n","        f'{classifier.name}_accuracies.csv',\n","        index=True)"]}],"metadata":{"colab":{"collapsed_sections":["yXfd3wEQLwmH","Y-kf2kqdmtKO","9qGCEYT38VHG","AXosnO4h8ZtX","kaP_79abm3V3","LOuegBRHfnXM","OTABK9YtfpF5","9dH-Ifejfo_w","AGKAjMGlfyj0","Zckpze_bv1uf","YNqNVdVtwX1W","4ssvzKUMwd2g","b0I3n4CDwgej","0tOTpmJ1tVoi","Xot8sYQxKQSk","wWhPOM4UKULN"],"provenance":[{"file_id":"1QiBU7EOpbyjVfl8B6t8J-KGe0cpOAPzl","timestamp":1669120323175}],"mount_file_id":"1QiBU7EOpbyjVfl8B6t8J-KGe0cpOAPzl","authorship_tag":"ABX9TyN1LZOMqC4fT9GfYzGzYBgs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}